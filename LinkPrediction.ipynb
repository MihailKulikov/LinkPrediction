{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LinkPrediction.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "i0vEZF6v4lbi"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_xPt3FwiyAf",
        "outputId": "26c4e841-1feb-4307-a808-93fff709c0d3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEe5rH39nZSd"
      },
      "source": [
        "gDrivePath = \"/content/drive/My Drive/Link prediction/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBaAAgyvTVCm",
        "outputId": "4f1c1eae-9225-42cc-e2c9-a664546bc9fc"
      },
      "source": [
        "!pip install -q pymorphy2\n",
        "!pip install -q bigartm10\n",
        "!pip install -q catboost"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 61kB 2.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.2MB 5.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.0MB 2.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 67.3MB 58kB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrFP7rgXpxRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10dd84a8-079e-4bde-c78a-dce6547c182b"
      },
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "import json, os, re\n",
        "from tqdm import tqdm as tq\n",
        "import pymorphy2\n",
        "import artm\n",
        "import numpy as np\n",
        "from scipy import spatial\n",
        "import networkx as nx\n",
        "from itertools import combinations\n",
        "import catboost as cgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "import scipy\n",
        "import matplotlib.pyplot   as plt\n",
        "from scipy import sparse\n",
        "from sklearn.metrics import roc_auc_score, precision_score, balanced_accuracy_score\n",
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, space_eval\n",
        "from catboost.utils import get_roc_curve, select_threshold\n",
        "from sklearn.metrics import balanced_accuracy_score, precision_recall_curve, auc, recall_score, f1_score, precision_score, classification_report"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import Iterable\n",
            "/usr/local/lib/python3.7/dist-packages/past/builtins/misc.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import Mapping\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKw8QRsYISvu"
      },
      "source": [
        "## Чистим текст"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWwa-HUgsuZb"
      },
      "source": [
        "def flatten(l):\n",
        "    return [item for sublist in l for item in sublist]\n",
        "\n",
        "def cleanNames(names_list):\n",
        "    expr = r'[А-ЯЁ]\\.[А-ЯЁ]\\. [А-ЯЁ][а-яё]*|[А-ЯЁ][а-яё]* [А-ЯЁ]\\.[А-ЯЁ]\\.'\n",
        "    filt_list = []\n",
        "    for name in names_list:\n",
        "        filt_list.append([x for x in re.findall(expr, name) if x != []])\n",
        "    filt_list2 = []\n",
        "    for l in flatten(filt_list):\n",
        "        x1, x2 = l.split(' ')\n",
        "        if x1.count('.') == 2:\n",
        "            filt_list2.append(l)\n",
        "        else:\n",
        "            filt_list2.append(' '.join([x2,x1]))\n",
        "    return filt_list2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GF6qheustGVN"
      },
      "source": [
        "json_files = os.listdir(gDrivePath + \"geofix/\")\n",
        "json_files.sort()\n",
        "df = pd.DataFrame(columns=['authors_raw', 'year', 'geo', 'geo_full', 'text'])\n",
        "\n",
        "for index, js in enumerate(json_files):\n",
        "    with open(os.path.join(gDrivePath + \"geofix/\", js)) as json_file:\n",
        "        json_text = json.load(json_file)\n",
        "        authors = json_text['authors_cleaned']\n",
        "        year = json_text['year']\n",
        "        geo = json_text['geo_tags']\n",
        "        geo_full = json_text['geo_tags_full']\n",
        "        text = json_text['text']\n",
        "        df.loc[index] = [authors, year, geo, geo_full, text]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdrZ-N9wf6S7"
      },
      "source": [
        "df['authors'] = df['authors_raw'].apply(cleanNames)\n",
        "df['year'] = df['year'].astype(int)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXoH18Y9VlZR"
      },
      "source": [
        "df = pd.read_csv(gDrivePath + 'initial_data_2015.csv')\n",
        "df.updated_geo = df.updated_geo.apply(eval)\n",
        "df.geo_full = df.geo_full.apply(eval)\n",
        "#df.to_csv(gDrivePath + 'initial_data.csv')\n",
        "#df.to_csv(gDrivePath + 'initial_data_2015.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEAz49UGnJBY"
      },
      "source": [
        "F = pd.read_csv(gDrivePath + 'F_2015.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V12OR28pg4Zg",
        "outputId": "3ba1ea2d-e719-459c-89e2-3287c26dc929"
      },
      "source": [
        "df[df.year==2016].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(302, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf0ydcs_LX_z"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "def set_geos(geos):\n",
        "  all_geos = geos.items()\n",
        "  authors = list(geos.keys())\n",
        "  geo_to_count = Counter([geo[1] for geo in all_geos if isinstance(geo[1], str)])\n",
        "  if len(geo_to_count) == 0:\n",
        "    for author in authors:\n",
        "      geos[author] = ''\n",
        "    return geos\n",
        "  frequent_geo = max(geo_to_count.items(), key = lambda kvp: kvp[1])[0]\n",
        "  for author in authors:\n",
        "    if not isinstance(geos[author], str):\n",
        "      geos[author] = frequent_geo\n",
        "  return geos\n",
        "\n",
        "df['updated_geo'] = df.geo_full.apply(set_geos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl9qpJoACigk"
      },
      "source": [
        "def remove_useless(row):\n",
        "  text = row['text']\n",
        "  index = row['index']\n",
        "  kw_index_en = text.find(\"Key words\")\n",
        "  kw_index_ru = text.find(\"Ключевые слова\")\n",
        "  email_index = text.find(\"E-mail\")\n",
        "  reference_index_en = text.find(\"Reference\")\n",
        "  reference_index_ru = text.find(\"Спиоск литературы\")\n",
        "  begin = 0\n",
        "  if kw_index_en > kw_index_ru:\n",
        "    begin = kw_index_en + len(\"key words\")\n",
        "  elif kw_index_en < kw_index_ru:\n",
        "    begin = kw_index_ru + len(\"Ключевые слова\")\n",
        "  end = len(text)\n",
        "  if reference_index_en < reference_index_ru:\n",
        "    end = reference_index_en\n",
        "  else:\n",
        "    end = reference_index_ru\n",
        "  center = text[begin:end]\n",
        "  words = [morph.parse(x.lower().replace(u'ё', u'е'))[0].normal_form\n",
        "           for x in re.findall(r'[ЁА-Яа-яё]+', center)\n",
        "           if len(x) > 2 and x != \"при\" and x != \"для\" and x != \"быть\" and x != \"что\" and x != \"рис\" and x != 'это' and x != 'где']\n",
        "  return str(index) + \" |words \" + \" \".join(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1xCRfTGF98b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e57b35f2-71f9-44c2-c9d7-4c07644361a7"
      },
      "source": [
        "morph = pymorphy2.MorphAnalyzer()\n",
        "vw = df.reset_index().apply(remove_useless, axis=1)\n",
        "vw.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pymorphy2/units/base.py:70: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "  args, varargs, kw, default = inspect.getargspec(cls.__init__)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0 |words надёжность трубопровод прочность расч...\n",
              "1    1 |words высоковязкий тяжёлый нефть сложнопост...\n",
              "2    2 |words ления тогурский свита как основной по...\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q68J3c1dPUqM"
      },
      "source": [
        "# with open(gDrivePath + 'vw_rp_2015.txt', 'w') as fout:\n",
        "#     for line in vw:\n",
        "#         fout.write(line + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDV_rRtPWTi8"
      },
      "source": [
        "# Строим тематические модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td8CwU5ZWOWV"
      },
      "source": [
        "# batch_vectorizer = artm.BatchVectorizer(data_path=gDrivePath + 'vw_rp_2015.txt', data_format='vowpal_wabbit', collection_name='vw', target_folder=gDrivePath + 'batches_rp_2015')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Tz6t2vjWOQd"
      },
      "source": [
        "batch_vectorizer = artm.BatchVectorizer(data_path=gDrivePath + 'batches_rp_2015', data_format = 'batches')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfQ2IqmMXYFS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88e27cb8-fa9d-4678-d1a0-2a0965c2b241"
      },
      "source": [
        "dictionary = artm.Dictionary()\n",
        "dictionary.gather(data_path=batch_vectorizer.data_path)\n",
        "dictionary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "artm.Dictionary(name=e9486bf5-c748-4157-839e-4bf3e9840727, num_entries=62841)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olNoWOB6XYBC"
      },
      "source": [
        "def print_topic_top_words(model, metric):\n",
        "    for topic_name in model.topic_names:\n",
        "      print(topic_name + ': '),\n",
        "      try:\n",
        "          print(\", \".join(model.score_tracker[metric].last_tokens[topic_name]))\n",
        "      except:\n",
        "          print(\"Not enough unigrams in a topic\")\n",
        "          print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFUicKXl4d4z"
      },
      "source": [
        "## PLSA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqyrkMBHXYL8"
      },
      "source": [
        "model_plsa = artm.ARTM(topic_names=['topic_{}'.format(i) for i in range(10)],\n",
        "                       scores=[artm.PerplexityScore(name='PerplexityScore',\n",
        "                                                    dictionary=dictionary)],\n",
        "                       cache_theta=True, reuse_theta=True, theta_columns_naming='title')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGiZEciBXYKr"
      },
      "source": [
        "model_plsa.scores.add(artm.SparsityPhiScore(name='SparsityPhiScoreP', class_id='words', eps=1e-5))\n",
        "model_plsa.scores.add(artm.SparsityThetaScore(name='SparsityThetaScoreP', eps=1e-5))\n",
        "model_plsa.scores.add(artm.TopTokensScore(name='TopTokensScoreP', num_tokens=10, class_id='words'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf_kJg79XYJh"
      },
      "source": [
        "model_plsa.initialize(dictionary=dictionary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsfOhXhzXYCX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b29d45b5-c9ce-406b-fbfe-458447863024"
      },
      "source": [
        "%%time\n",
        "model_plsa.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 2s, sys: 1.12 s, total: 1min 3s\n",
            "Wall time: 50 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BIsWy5v0lGI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1baac6a2-5bbd-4c3b-f551-786c22819d9a"
      },
      "source": [
        "print_topic_top_words(model_plsa, 'TopTokensScoreP')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "topic_0: \n",
            "пласт, коллектор, порода, скважина, данные, исследование, керн, пористость, результат, проницаемость\n",
            "topic_1: \n",
            "отложение, порода, значение, месторождение, углеводород, нефтяной, работа, зона, нефть, быть\n",
            "topic_2: \n",
            "нефтяной, система, работа, исследование, использование, хозяйство, который, установка, применение, технология\n",
            "topic_3: \n",
            "давление, нефть, газ, нефтяной, коэффициент, вода, значение, зависимость, расчёт, жидкость\n",
            "topic_4: \n",
            "нефть, скважина, месторождение, разработка, пласт, нефтяной, добыча, запас, технология, вода\n",
            "topic_5: \n",
            "нефть, раствор, состав, температура, вода, образец, нефтяной, содержание, порода, месторождение\n",
            "topic_6: \n",
            "скважина, трещина, грп, давление, пласт, бурение, ствол, колонна, работа, жидкость\n",
            "topic_7: \n",
            "модель, система, данные, решение, работа, оценка, расчёт, параметр, проект, объект\n",
            "topic_8: \n",
            "нефтяной, нефть, оао, компания, быть, месторождение, работа, год, газ, который\n",
            "topic_9: \n",
            "отложение, зона, порода, часть, разрез, западный, работа, свита, который, нефть\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBckL4TQ6V6o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59643e71-0d38-4256-e9a5-474d4f7f1b8d"
      },
      "source": [
        "print(model_plsa.score_tracker['SparsityPhiScoreP'].last_value)\n",
        "print(model_plsa.score_tracker['SparsityThetaScoreP'].last_value)\n",
        "theta0 = model_plsa.get_theta()\n",
        "print('Num zeros col in theta: ', sum([(theta0[i] == 0).all() for i in theta0.columns]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.903433620929718\n",
            "0.5809407830238342\n",
            "Num zeros col in theta:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSo5vK34kxfa"
      },
      "source": [
        "# F = model_plsa.get_theta()\n",
        "# F.to_csv(gDrivePath+f'/data/plsa_theta.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq0_BMei4pKl"
      },
      "source": [
        "## LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB0xN6tSjUAo"
      },
      "source": [
        "model_lda = artm.ARTM(topic_names=['topic_{}'.format(i) for i in range(14)],\n",
        "                       scores=[artm.PerplexityScore(name='PerplexityScore',\n",
        "                                                    dictionary=dictionary)],\n",
        "                       regularizers=[artm.SmoothSparseThetaRegularizer(name='SparseTheta', tau=-0.7),\n",
        "                                     artm.SmoothSparsePhiRegularizer(name='SparsePhi', tau=-0.1)],\n",
        "                       cache_theta=True, reuse_theta=True, theta_columns_naming='title')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMnspgCCmZfY"
      },
      "source": [
        "model_lda.scores.add(artm.SparsityPhiScore(name='SparsityPhiScoreL', class_id='words', eps=1e-5))\n",
        "model_lda.scores.add(artm.SparsityThetaScore(name='SparsityThetaScoreL', eps=1e-5))\n",
        "model_lda.scores.add(artm.TopTokensScore(name='TopTokensScoreL', num_tokens=15, class_id='words'))\n",
        "model_lda.initialize(dictionary=dictionary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN3D7eHzmd9r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2bc5903-e0e5-4b4e-a810-f59f4ece52dc"
      },
      "source": [
        "%%time\n",
        "model_lda.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 13s, sys: 1.27 s, total: 1min 14s\n",
            "Wall time: 59.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ha7Lx_eRuevm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f03cce4-97dc-4198-c078-ef1aeb8a9efe"
      },
      "source": [
        "print(model_lda.score_tracker['SparsityPhiScoreL'].last_value)\n",
        "print(model_lda.score_tracker['SparsityThetaScoreL'].last_value)\n",
        "theta0 = model_lda.get_theta()\n",
        "print('Num zeros col in theta: ', sum([(theta0[i] == 0).all() for i in theta0.columns]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9135684967041016\n",
            "0.6130807399749756\n",
            "Num zeros col in theta:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTAVeiZZuV4R"
      },
      "source": [
        "print_topic_top_words(model_lda, 'TopTokensScoreL')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE8wY8sgmtnY"
      },
      "source": [
        "# F = model_lda.get_theta()\n",
        "# F.to_csv(gDrivePath+'/data/lda_theta.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0vEZF6v4lbi"
      },
      "source": [
        "## ARTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6g32ZmP6Zih"
      },
      "source": [
        "model_artm = artm.ARTM(topic_names=['topic_{}'.format(i) for i in range(9)],\n",
        "                       scores=[artm.PerplexityScore(name='PerplexityScore',\n",
        "                                                    dictionary=dictionary)],\n",
        "                       regularizers=[artm.SmoothSparseThetaRegularizer(name='SparseTheta', tau=-0.5),\n",
        "                                     artm.SmoothSparsePhiRegularizer(name='SparsePhi', tau=-0.001)],\n",
        "                       cache_theta=True, reuse_theta=True, theta_columns_naming='title')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHRKzgZ30Lxt"
      },
      "source": [
        "model_artm.regularizers.add(artm.DecorrelatorPhiRegularizer(name='DecorrelatorPhi', tau=-50e3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VXFagbb0Lun"
      },
      "source": [
        "model_artm.scores.add(artm.SparsityPhiScore(name='SparsityPhiScoreA', class_id='words', eps=1e-5))\n",
        "model_artm.scores.add(artm.SparsityThetaScore(name='SparsityThetaScoreA', eps=1e-5))\n",
        "model_artm.scores.add(artm.TopTokensScore(name='TopTokensScoreA', num_tokens=15, class_id='words'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4O4gFaM0LsL"
      },
      "source": [
        "model_artm.initialize(dictionary=dictionary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGFwT1pZ0RPm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "94c7dc2b-c29f-49b5-87c6-1cbcaf2393bb"
      },
      "source": [
        "%%time\n",
        "model_artm.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-89265d633e29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model_artm.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=25)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/artm/artm_model.py\u001b[0m in \u001b[0;36mfit_offline\u001b[0;34m(self, batch_vectorizer, num_collection_passes, reset_nwt)\u001b[0m\n\u001b[1;32m    579\u001b[0m                     self._pool.apply_async(func=self.master.fit_offline,\n\u001b[1;32m    580\u001b[0m                                            args=(batch_vectorizer.batches_ids,\n\u001b[0;32m--> 581\u001b[0;31m                                                  batch_vectorizer.weights, 1, None, reset_nwt)),\n\u001b[0m\u001b[1;32m    582\u001b[0m                     batch_vectorizer.num_batches)\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/artm/artm_model.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, args)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__deepcopy__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/artm/master_component.py\u001b[0m in \u001b[0;36mfit_offline\u001b[0;34m(self, batch_filenames, batch_weights, num_collection_passes, batches_folder, reset_nwt)\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatches_folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArtmFitOfflineMasterModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaster_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m     def fit_online(self, batch_filenames=None, batch_weights=None, update_after=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/artm/wrapper/api.py\u001b[0m in \u001b[0;36martm_api_call\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mc_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UuckHpn0RhL"
      },
      "source": [
        "print(model_artm.score_tracker['SparsityPhiScoreA'].last_value)\n",
        "print(model_artm.score_tracker['SparsityThetaScoreA'].last_value)\n",
        "theta0 = model_artm.get_theta()\n",
        "print('Num zeros col in theta: ', sum([(theta0[i] == 0).all() for i in theta0.columns]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YHangAA0RZ2"
      },
      "source": [
        "print_topic_top_words(model_artm, 'TopTokensScoreA')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp6dCmaQjmO_"
      },
      "source": [
        "F = model_artm.get_theta()\n",
        "# F.to_csv(gDrivePath+f'/data/artm_theta.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JameXoMNVFc"
      },
      "source": [
        "## Иерархическая"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShYFlPRH3ref"
      },
      "source": [
        "hier = artm.hARTM(scores=[artm.PerplexityScore(name='PerplexityScore', dictionary=dictionary)],\n",
        "                  cache_theta=True, reuse_theta=True, theta_columns_naming='title')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVQzTUJodGiG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49366f3a-e314-4929-e7cf-6780fabefcc5"
      },
      "source": [
        "level0 = hier.add_level(num_topics=9)\n",
        "level0.initialize(dictionary)\n",
        "level0.regularizers.add(artm.DecorrelatorPhiRegularizer(name='DecorrelatorPhi0', tau=5e3))\n",
        "level0.regularizers.add(artm.SmoothSparseThetaRegularizer(name='SparseTheta', tau=-0.5))\n",
        "level0.regularizers.add(artm.SmoothSparsePhiRegularizer(name='SparsePhi', tau=-0.1))\n",
        "\n",
        "level0.scores.add(artm.SparsityPhiScore(name='SparsityPhiScore0', class_id='words', eps=1e-5))\n",
        "level0.scores.add(artm.SparsityThetaScore(name='SparsityThetaScore0', eps=1e-5))\n",
        "%time level0.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 32.3 s, sys: 476 ms, total: 32.8 s\n",
            "Wall time: 23 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrO95jm9cwKV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2639e72-8f5a-4af9-a8b9-dec279ee68db"
      },
      "source": [
        "print('level0')\n",
        "print('SparsityPhi: ', level0.score_tracker['SparsityPhiScore0'].last_value)\n",
        "print('SparsityTheta: ', level0.score_tracker['SparsityThetaScore0'].last_value)\n",
        "theta0 = level0.get_theta()\n",
        "print('Num zeros col in theta: ', sum([(theta0[i] == 0).all() for i in theta0.columns]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "level0\n",
            "SparsityPhi:  0.9107341170310974\n",
            "SparsityTheta:  0.49851495027542114\n",
            "Num zeros col in theta:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVi3G5sBdlFQ"
      },
      "source": [
        "level1 = hier.add_level(num_topics=50, topic_names=['child_topic_' + str(i) for i in range(25)], parent_level_weight=1)\n",
        "level1.scores.add(artm.SparsityPhiScore(name='SparsityPhiScore1', class_id='words', eps=1e-5))\n",
        "level1.scores.add(artm.SparsityThetaScore(name='SparsityThetaScore1', eps=1e-5))\n",
        "level1.scores.add(artm.TopTokensScore(name='TopTokensScore1', num_tokens=15, class_id='words'))\n",
        "level1.regularizers.add(artm.HierarchySparsingThetaRegularizer(name=\"HierSp\", tau=2),overwrite=True)\n",
        "level1.regularizers.add(artm.SmoothSparsePhiRegularizer(name='SparsePhi', tau=-0.1),overwrite=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpJIGbm9gNaX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fb950ea-1569-4909-cf4d-bb124c293704"
      },
      "source": [
        "level1.initialize(dictionary)\n",
        "level1.regularizers.add(artm.SmoothSparseThetaRegularizer(name='SparseTheta', tau=-0.01),overwrite=True)\n",
        "level1.regularizers.add(artm.DecorrelatorPhiRegularizer(name='DecorrelatorPhi1', tau=15e4),overwrite=True)\n",
        "%time level1.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 54.2 s, sys: 813 ms, total: 55 s\n",
            "Wall time: 35.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBxBWR5_ZIqy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75f99f86-abe0-4d69-ae65-d21b2e074586"
      },
      "source": [
        "print('level1')\n",
        "print('SparsityPhi: ', level1.score_tracker['SparsityPhiScore1'].last_value)\n",
        "print('SparsityTheta: ', level1.score_tracker['SparsityThetaScore1'].last_value)\n",
        "theta1 = level1.get_theta()\n",
        "print('Num zeros col in theta: ',sum([(theta1[i] == 0).all() for i in theta1.columns]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "level1\n",
            "SparsityPhi:  0.9150694608688354\n",
            "SparsityTheta:  0.6169210076332092\n",
            "Num zeros col in theta:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF1ctJyRdfNV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e80cd8a9-f4dc-486b-a1a7-1bab71e93708"
      },
      "source": [
        "print_topic_top_words(level1, 'TopTokensScore1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "child_topic_0: \n",
            "модель, нефть, значение, данные, результат, пласт, нефтяной, разработка, параметр, быть, получить, вытеснение, моделирование, зависимость, метод\n",
            "child_topic_1: \n",
            "образец, порода, керн, исследование, вода, зависимость, метод, проницаемость, коэффициент, поровый, скорость, значение, измерение, нефтяной, параметр\n",
            "child_topic_2: \n",
            "газ, энергия, сепаратор, поток, нефтяной, ротор, процесс, мощность, частота, сепарация, использование, нефтепровод, нефть, турбина, где\n",
            "child_topic_3: \n",
            "коррозия, трубопровод, коррозионный, защита, ингибитор, сеть, система, битум, среда, испытание, кислотный, время, год, обработка, фотография\n",
            "child_topic_4: \n",
            "год, нефть, разработка, оао, быть, страна, кислота, млн, новый, который, компания, сша, реагент, нефтегазовый, институт\n",
            "child_topic_5: \n",
            "содержание, отложение, территория, вещество, органический, толща, южный, генерация, условие, бассейн, оценка, район, впадина, нефтяной, зона\n",
            "child_topic_6: \n",
            "давление, скважина, трещина, пласт, разработка, месторождение, нефтяной, расчёт, пластовый, мпа, эксплуатация, который, нефть, результат, время\n",
            "child_topic_7: \n",
            "нефть, нефтяной, газ, месторождение, состав, технология, температура, добыча, хозяйство, пласт, кислотный, быть, после, исследование, применение\n",
            "child_topic_8: \n",
            "скважина, насос, колонна, бурение, жидкость, оборудование, труба, диаметр, давление, установка, рабочий, работа, система, технология, который\n",
            "child_topic_9: \n",
            "скважина, месторождение, пласт, разработка, нефть, запас, участок, технология, нефтяной, вода, добыча, объект, применение, скв, залежь\n",
            "child_topic_10: \n",
            "нефть, вода, нефтяной, давление, фаза, температура, процесс, вязкость, газ, система, скорость, эмульсия, объём, пластовый, смесь\n",
            "child_topic_11: \n",
            "нефть, который, процесс, новый, разработка, модель, решение, нефтяной, задача, данные, метод, анализ, работа, система, реализация\n",
            "child_topic_12: \n",
            "модель, параметр, скважина, расчёт, система, решение, бурение, нефтяной, точка, это, алгоритм, моделирование, который, результат, задача\n",
            "child_topic_13: \n",
            "нефтепродукт, вода, работа, год, пдк, оао, бурение, участок, новый, экологический, уровень, состояние, объект, грунт, безопасность\n",
            "child_topic_14: \n",
            "раствор, состав, цементный, тампонажный, прочность, свойство, частица, плотность, механический, камень, вода, добавка, буровой, примесь, условие\n",
            "child_topic_15: \n",
            "порода, свита, углеводород, баженовский, отложение, состав, глинистый, западный, органический, вещество, исследование, разрез, результат, часть, который\n",
            "child_topic_16: \n",
            "пласт, коллектор, месторождение, зона, скважина, нефть, запас, отложение, залежь, горизонт, нефтяной, порода, геолого, карбонатный, вероятность\n",
            "child_topic_17: \n",
            "скважина, грп, дебит, нефть, ствол, эксплуатация, работа, жидкость, добыча, давление, пласт, нефтяной, горизонтальный, технология, режим\n",
            "child_topic_18: \n",
            "газ, температура, метод, содержание, углеводород, горение, реакция, пластовый, состав, фракция, процесс, компонент, нефтяной, окисление, эксперимент\n",
            "child_topic_19: \n",
            "компания, оао, система, проект, объект, месторождение, работа, управление, технология, нефтяной, добыча, развитие, решение, ооо, технический\n",
            "child_topic_20: \n",
            "раствор, буровой, бурение, показатель, условие, почва, материал, отход, соль, вода, процесс, являться, основа, качество, водный\n",
            "child_topic_21: \n",
            "отложение, зона, коллектор, месторождение, залежь, разрез, пласт, карбонатный, часть, структура, нефть, порода, тип, пористость, разведочный\n",
            "child_topic_22: \n",
            "порода, работа, трещина, скважина, развитие, отложение, интервал, результат, сейсмический, данные, геология, западный, залежь, это, горизонт\n",
            "child_topic_23: \n",
            "трубопровод, образец, температура, поверхность, коэффициент, труба, скорость, который, сопротивление, грунт, значение, слой, время, при, для\n",
            "child_topic_24: \n",
            "пласт, метод, исследование, параметр, модель, данные, месторождение, коллектор, проницаемость, керн, гис, результат, это, скважина, анализ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNlKf8vFL6aP"
      },
      "source": [
        "## Визуализатор"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "g9-5pw2epBst",
        "outputId": "8adf6030-4380-464b-effa-d7e08532ebba"
      },
      "source": [
        "theta_T = level1.get_theta().T\n",
        "phi_T = level1.get_phi().T\n",
        "phi_T.columns = phi_T.columns.to_series().apply(lambda name: name[1])\n",
        "phi_T.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>нерезультативный</th>\n",
              "      <th>документироваться</th>\n",
              "      <th>мотивационный</th>\n",
              "      <th>действенность</th>\n",
              "      <th>перениматься</th>\n",
              "      <th>институционализация</th>\n",
              "      <th>риваля</th>\n",
              "      <th>союзнефтеотдача</th>\n",
              "      <th>щелкачев</th>\n",
              "      <th>универсиитат</th>\n",
              "      <th>шоболово</th>\n",
              "      <th>анссср</th>\n",
              "      <th>жигач</th>\n",
              "      <th>краковский</th>\n",
              "      <th>надя</th>\n",
              "      <th>фосфатокремнистый</th>\n",
              "      <th>гиммельфарбский</th>\n",
              "      <th>электродрель</th>\n",
              "      <th>шлифовать</th>\n",
              "      <th>колпачок</th>\n",
              "      <th>стеклянрация</th>\n",
              "      <th>прудить</th>\n",
              "      <th>безрис</th>\n",
              "      <th>упереться</th>\n",
              "      <th>дубна</th>\n",
              "      <th>мантсгео</th>\n",
              "      <th>катор</th>\n",
              "      <th>батскома</th>\n",
              "      <th>пго</th>\n",
              "      <th>уинский</th>\n",
              "      <th>ангасякнуть</th>\n",
              "      <th>василовский</th>\n",
              "      <th>кереметовый</th>\n",
              "      <th>недеспергировать</th>\n",
              "      <th>довытеснять</th>\n",
              "      <th>гированная</th>\n",
              "      <th>недиспер</th>\n",
              "      <th>ромм</th>\n",
              "      <th>полутоновый</th>\n",
              "      <th>брокеридж</th>\n",
              "      <th>...</th>\n",
              "      <th>новаторство</th>\n",
              "      <th>следовано</th>\n",
              "      <th>термобурение</th>\n",
              "      <th>чугорьяхинский</th>\n",
              "      <th>ааний</th>\n",
              "      <th>парус</th>\n",
              "      <th>типоразмерный</th>\n",
              "      <th>ипполитовский</th>\n",
              "      <th>исследопараметр</th>\n",
              "      <th>тимкий</th>\n",
              "      <th>шпицберген</th>\n",
              "      <th>апрельмать</th>\n",
              "      <th>сдуваться</th>\n",
              "      <th>голофаста</th>\n",
              "      <th>расщелина</th>\n",
              "      <th>пилообразность</th>\n",
              "      <th>малообеспеченный</th>\n",
              "      <th>тёртый</th>\n",
              "      <th>бравичев</th>\n",
              "      <th>агодарность</th>\n",
              "      <th>клячкина</th>\n",
              "      <th>ярославцев</th>\n",
              "      <th>предпоказатель</th>\n",
              "      <th>канапый</th>\n",
              "      <th>торошение</th>\n",
              "      <th>сэлида</th>\n",
              "      <th>барсуковдлить</th>\n",
              "      <th>оставот</th>\n",
              "      <th>преимущпптч</th>\n",
              "      <th>отобранлять</th>\n",
              "      <th>улучшаться</th>\n",
              "      <th>месторождефициент</th>\n",
              "      <th>керногост</th>\n",
              "      <th>внутхимически</th>\n",
              "      <th>ефимец</th>\n",
              "      <th>долговременный</th>\n",
              "      <th>посредством</th>\n",
              "      <th>мегафациальный</th>\n",
              "      <th>титаномагнетит</th>\n",
              "      <th>ильменит</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>child_topic_0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.492411e-07</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>child_topic_1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000043</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>child_topic_2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000054</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000061</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>child_topic_3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000054</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>child_topic_4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 62841 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               нерезультативный  документироваться  ...  титаномагнетит  ильменит\n",
              "child_topic_0               0.0                0.0  ...             0.0       0.0\n",
              "child_topic_1               0.0                0.0  ...             0.0       0.0\n",
              "child_topic_2               0.0                0.0  ...             0.0       0.0\n",
              "child_topic_3               0.0                0.0  ...             0.0       0.0\n",
              "child_topic_4               0.0                0.0  ...             0.0       0.0\n",
              "\n",
              "[5 rows x 62841 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvDq5T8lzxBI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89f756ae-5ec0-42c2-a7dd-611630d6a636"
      },
      "source": [
        "!pip install -q pyldavis\n",
        "import pyLDAvis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▏                               | 10kB 24.3MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 30.5MB/s eta 0:00:01\r\u001b[K     |▋                               | 30kB 26.9MB/s eta 0:00:01\r\u001b[K     |▉                               | 40kB 30.2MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 28.5MB/s eta 0:00:01\r\u001b[K     |█▏                              | 61kB 30.8MB/s eta 0:00:01\r\u001b[K     |█▍                              | 71kB 20.1MB/s eta 0:00:01\r\u001b[K     |█▋                              | 81kB 20.6MB/s eta 0:00:01\r\u001b[K     |█▉                              | 92kB 19.9MB/s eta 0:00:01\r\u001b[K     |██                              | 102kB 20.0MB/s eta 0:00:01\r\u001b[K     |██▏                             | 112kB 20.0MB/s eta 0:00:01\r\u001b[K     |██▍                             | 122kB 20.0MB/s eta 0:00:01\r\u001b[K     |██▋                             | 133kB 20.0MB/s eta 0:00:01\r\u001b[K     |██▊                             | 143kB 20.0MB/s eta 0:00:01\r\u001b[K     |███                             | 153kB 20.0MB/s eta 0:00:01\r\u001b[K     |███▏                            | 163kB 20.0MB/s eta 0:00:01\r\u001b[K     |███▍                            | 174kB 20.0MB/s eta 0:00:01\r\u001b[K     |███▋                            | 184kB 20.0MB/s eta 0:00:01\r\u001b[K     |███▊                            | 194kB 20.0MB/s eta 0:00:01\r\u001b[K     |████                            | 204kB 20.0MB/s eta 0:00:01\r\u001b[K     |████▏                           | 215kB 20.0MB/s eta 0:00:01\r\u001b[K     |████▍                           | 225kB 20.0MB/s eta 0:00:01\r\u001b[K     |████▋                           | 235kB 20.0MB/s eta 0:00:01\r\u001b[K     |████▊                           | 245kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 256kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 266kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 276kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 286kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 296kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 307kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 317kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 327kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 337kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 348kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████                         | 358kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 368kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 378kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 389kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 399kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 409kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 419kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 430kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 440kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 450kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████                       | 460kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 471kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 481kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 491kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 501kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 512kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 522kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 532kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 542kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 552kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 563kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 573kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 583kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 593kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 604kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 614kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 624kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 634kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 645kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 655kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 665kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 675kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 686kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 696kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 706kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 716kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 727kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 737kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 747kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 757kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 768kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 778kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 788kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 798kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 808kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 819kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████                | 829kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 839kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 849kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 860kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 870kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 880kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 890kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 901kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 911kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 921kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 931kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 942kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 952kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 962kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 972kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 983kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 993kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.0MB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.0MB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.0MB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.0MB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.0MB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.1MB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.1MB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.1MB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.1MB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.1MB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.1MB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.1MB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.1MB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.1MB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.1MB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.2MB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.2MB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.2MB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.2MB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.2MB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.2MB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.2MB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.2MB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.2MB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.2MB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.3MB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.3MB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.3MB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.3MB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.3MB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.3MB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.3MB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.3MB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.3MB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.4MB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.4MB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.4MB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.4MB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.4MB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.4MB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.4MB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.4MB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.4MB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.4MB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.5MB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.5MB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.5MB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.5MB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.5MB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.5MB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.5MB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.5MB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.5MB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.5MB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.6MB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.6MB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.6MB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.6MB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.6MB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.6MB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.6MB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.6MB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.6MB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.6MB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.7MB 20.0MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 15.3MB 211kB/s \n",
            "\u001b[K     |████████████████████████████████| 9.9MB 50.2MB/s \n",
            "\u001b[?25h  Building wheel for pyldavis (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.20.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 1.2.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6IfGROYVAM8"
      },
      "source": [
        "doc_lengths = []\n",
        "with open(gDrivePath + 'vw_rp_2015.txt', 'r') as file:\n",
        "    for i in range(1459):\n",
        "        words = file.readline().split()[2:]\n",
        "        doc_lengths.append(len(words))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NN4ZVzkz0zV4",
        "outputId": "32cb3351-0a3e-41f3-ebe4-7950a744ceaf"
      },
      "source": [
        "html = pyLDAvis.prepare(topic_term_dists = phi_T.values, \n",
        "                        doc_topic_dists = theta_T.values, \n",
        "                        doc_lengths = doc_lengths,\n",
        "                        vocab = phi_T.columns,\n",
        "                        term_frequency = dictionary._master.get_dictionary(dictionary._name).token_tf,\n",
        "                        R = 15)\n",
        "\n",
        "pyLDAvis.save_html(html, 'hARTM.html')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyLDAvis/_prepare.py:235: RuntimeWarning: divide by zero encountered in log\n",
            "  log_1 = np.log(pd.eval(\"topic_given_term.T / topic_proportion\"))\n",
            "/usr/local/lib/python3.7/dist-packages/pyLDAvis/_prepare.py:258: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lift = np.log(pd.eval(\"topic_term_dists / term_proportion\")).astype(\"float64\")\n",
            "/usr/local/lib/python3.7/dist-packages/pyLDAvis/_prepare.py:259: RuntimeWarning: divide by zero encountered in log\n",
            "  log_ttd = np.log(pd.eval(\"topic_term_dists\")).astype(\"float64\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ek-7vvroOOSK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "f34c1db9-b383-48a8-99f3-0523e1014be8"
      },
      "source": [
        "F = level1.get_theta()\n",
        "F.to_csv(gDrivePath + 'F_2015.csv', index=False)\n",
        "F.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>1419</th>\n",
              "      <th>1420</th>\n",
              "      <th>1421</th>\n",
              "      <th>1422</th>\n",
              "      <th>1423</th>\n",
              "      <th>1424</th>\n",
              "      <th>1425</th>\n",
              "      <th>1426</th>\n",
              "      <th>1427</th>\n",
              "      <th>1428</th>\n",
              "      <th>1429</th>\n",
              "      <th>1430</th>\n",
              "      <th>1431</th>\n",
              "      <th>1432</th>\n",
              "      <th>1433</th>\n",
              "      <th>1434</th>\n",
              "      <th>1435</th>\n",
              "      <th>1436</th>\n",
              "      <th>1437</th>\n",
              "      <th>1438</th>\n",
              "      <th>1439</th>\n",
              "      <th>1440</th>\n",
              "      <th>1441</th>\n",
              "      <th>1442</th>\n",
              "      <th>1443</th>\n",
              "      <th>1444</th>\n",
              "      <th>1445</th>\n",
              "      <th>1446</th>\n",
              "      <th>1447</th>\n",
              "      <th>1448</th>\n",
              "      <th>1449</th>\n",
              "      <th>1450</th>\n",
              "      <th>1451</th>\n",
              "      <th>1452</th>\n",
              "      <th>1453</th>\n",
              "      <th>1454</th>\n",
              "      <th>1455</th>\n",
              "      <th>1456</th>\n",
              "      <th>1457</th>\n",
              "      <th>1458</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>child_topic_0</th>\n",
              "      <td>0.134406</td>\n",
              "      <td>0.204902</td>\n",
              "      <td>0.045138</td>\n",
              "      <td>0.064067</td>\n",
              "      <td>0.084834</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018568</td>\n",
              "      <td>0.249968</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.064552</td>\n",
              "      <td>0.367752</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125279</td>\n",
              "      <td>0.22238</td>\n",
              "      <td>0.145606</td>\n",
              "      <td>0.06948</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.202819</td>\n",
              "      <td>0.267235</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.184371</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.117757</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.247175</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.189715</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007330</td>\n",
              "      <td>0.155371</td>\n",
              "      <td>0.416560</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.023698</td>\n",
              "      <td>0.096062</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000296</td>\n",
              "      <td>0.002725</td>\n",
              "      <td>0.053124</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.075344</td>\n",
              "      <td>0.412305</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.479758</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001240</td>\n",
              "      <td>0.006598</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.155748</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000193</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.110614</td>\n",
              "      <td>0.198281</td>\n",
              "      <td>0.084979</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.446223</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.528358</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.016148</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.258498</td>\n",
              "      <td>0.009515</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.250976</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.154698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>child_topic_1</th>\n",
              "      <td>0.000327</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006622</td>\n",
              "      <td>0.008659</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.003041</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.047457</td>\n",
              "      <td>0.035524</td>\n",
              "      <td>0.082453</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.030145</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.004926</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002398</td>\n",
              "      <td>0.033209</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007542</td>\n",
              "      <td>0.195646</td>\n",
              "      <td>0.013288</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.189715</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.067771</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.190584</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001319</td>\n",
              "      <td>0.021922</td>\n",
              "      <td>0.000471</td>\n",
              "      <td>0.000706</td>\n",
              "      <td>0.147675</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004122</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.012063</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.124950</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.090529</td>\n",
              "      <td>0.070760</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.078979</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.126049</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002462</td>\n",
              "      <td>0.004701</td>\n",
              "      <td>0.215787</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018337</td>\n",
              "      <td>0.071560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>child_topic_2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.084650</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.16295</td>\n",
              "      <td>0.004271</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018093</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007220</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000643</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006206</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.245277</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020182</td>\n",
              "      <td>0.008210</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000262</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.494355</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006138</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>child_topic_3</th>\n",
              "      <td>0.087949</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.429327</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.056108</td>\n",
              "      <td>0.005256</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.019349</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007322</td>\n",
              "      <td>0.000106</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001308</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000408</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000128</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.038816</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000306</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004093</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>child_topic_4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003048</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005777</td>\n",
              "      <td>0.004404</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.022946</td>\n",
              "      <td>0.076088</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.033495</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.010543</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.052317</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.052001</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.615114</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.025542</td>\n",
              "      <td>0.004436</td>\n",
              "      <td>0.001532</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011946</td>\n",
              "      <td>0.001032</td>\n",
              "      <td>0.031119</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.177563</td>\n",
              "      <td>0.042746</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.062161</td>\n",
              "      <td>0.001522</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.264603</td>\n",
              "      <td>0.207561</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.024908</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000913</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1459 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      0         1         2  ...      1456      1457      1458\n",
              "child_topic_0  0.134406  0.204902  0.045138  ...  0.250976  0.000000  0.154698\n",
              "child_topic_1  0.000327  0.000000  0.000000  ...  0.000000  0.018337  0.071560\n",
              "child_topic_2  0.000000  0.000000  0.000000  ...  0.000000  0.006138  0.000000\n",
              "child_topic_3  0.087949  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "child_topic_4  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000913\n",
              "\n",
              "[5 rows x 1459 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntubjMbxHSXh"
      },
      "source": [
        "# theta0.to_csv(gDrivePath+'/data/hier_theta_0.csv')\n",
        "# theta1.to_csv(gDrivePath+'/data/hier_theta_1.csv')\n",
        "# psi = level1.get_psi()\n",
        "# psi.to_csv(gDrivePath+'/data/hier_psi_1.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu5miS8afnV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68858299-13f1-48f1-d7ae-d6b1d26490c8"
      },
      "source": [
        "# with open(gDrivePath+'/data/phi1.batch', 'w') as f:\n",
        "#     f.write('phi1.batch')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3143"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn6MfCKsHZ0m"
      },
      "source": [
        "# Авторы"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hqou8SE0VHDk"
      },
      "source": [
        "def normalize_geo(geo):\n",
        "  geo = re.sub(r'[%s]' % re.escape(r\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_«»“”’*…/_.\\\\`{|}~\"\"\"), '', geo).strip()\n",
        "  words = geo.split()\n",
        "  if len(words) == 0:\n",
        "    return \"\"\n",
        "  if words[0] == \"Institute\":\n",
        "    return \" \".join(words[:3])\n",
        "  elif words[0] == \"et\" or words[0] == \"at\":\n",
        "    return \"\"\n",
        "  else:\n",
        "    return \" \".join(words[:2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZxdFaEz28oF"
      },
      "source": [
        "def create_graph(frame):\n",
        "    G = nx.Graph()\n",
        "    for i, row in frame.iterrows():\n",
        "        authors = list(row['updated_geo'].items())\n",
        "        if len(authors) == 1:\n",
        "            try:\n",
        "              geo = normalize_geo(authors[0][1])\n",
        "            except AttributeError:\n",
        "              geo = ''\n",
        "            G.add_node(authors[0][0], geo = geo)\n",
        "        else:\n",
        "            for auth1, auth2 in combinations(authors, 2):\n",
        "                try:\n",
        "                    geo1 = normalize_geo(auth1[1])\n",
        "                except AttributeError:\n",
        "                    geo1 = ''\n",
        "                try:\n",
        "                    geo2 = normalize_geo(auth2[1])\n",
        "                except AttributeError:\n",
        "                    geo2 = ''\n",
        "                    \n",
        "                G.add_node(auth1[0], geo=geo1)\n",
        "                G.add_node(auth2[0], geo=geo2)\n",
        "                G.add_edge(auth1[0], auth2[0])\n",
        "    return G"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjCGg_PjfKBY"
      },
      "source": [
        "paper_to_authors = df.geo_full.apply(lambda geos: list(geos.keys())).to_dict()\n",
        "unique_authors = []\n",
        "for authors in df.geo_full.apply(lambda geos: geos.keys()).tolist():\n",
        "  unique_authors += authors\n",
        "unique_authors = list(set(unique_authors))\n",
        "author_to_papers = dict.fromkeys(unique_authors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPDPdlg3ubi_"
      },
      "source": [
        "for paper in F.columns:\n",
        "  for author in paper_to_authors[int(paper)]:\n",
        "    if author_to_papers[author] is None:\n",
        "      author_to_papers[author] = [F[paper].tolist()]\n",
        "    else:\n",
        "      author_to_papers[author].append(F[paper].tolist())\n",
        "for author in author_to_papers.keys():\n",
        "  author_to_papers[author] = np.array(author_to_papers[author])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBkNozWMfIar"
      },
      "source": [
        "author_to_vec = dict()\n",
        "for author in author_to_papers.keys():\n",
        "  author_to_vec[author] = np.mean(author_to_papers[author], axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVrMEwBm16RJ"
      },
      "source": [
        "def S(u_vec, v_vec):\n",
        "  return 1 / np.exp(spatial.distance.cosine(u_vec, v_vec))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU5kso0l82K0"
      },
      "source": [
        "def SIM(u_name, v_name, G, F):\n",
        "  s = S(author_to_vec[u_name], author_to_vec[v_name])\n",
        "  neighbors = nx.common_neighbors(G, u_name, v_name)\n",
        "  norm = 0\n",
        "  sum = 0\n",
        "  for neighbor in neighbors:\n",
        "    norm += 1\n",
        "    uz_papers = np.array([F[str(paper)] for paper in paper_to_authors.keys()\n",
        "                    if neighbor in paper_to_authors[paper]\n",
        "                    and u_name in paper_to_authors[paper]])\n",
        "    vz_papers = np.array([F[str(paper)] for paper in paper_to_authors.keys()\n",
        "                    if neighbor in paper_to_authors[paper]\n",
        "                    and v_name in paper_to_authors[paper]])\n",
        "    x_uz = np.mean(uz_papers, axis=0)\n",
        "    x_vz = np.mean(vz_papers, axis=0)\n",
        "    sum += S(x_uz, x_vz)\n",
        "  if sum == 0:\n",
        "    return s\n",
        "  else:\n",
        "    return s / norm * sum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpEeSqW4JX5I"
      },
      "source": [
        "def add_sim(G, F):\n",
        "  for (u, v) in G.edges():\n",
        "    G.add_edge(u, v, sim = SIM(u, v, G, F))\n",
        "  return G"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2lSBFZlc98X",
        "outputId": "f46579c6-f640-4b2f-9165-bfc4ea1c1933"
      },
      "source": [
        "df.updated_geo.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    {'d.g. nerodenko': 'Tyumen State Oil and Gas U...\n",
              "1            {'n.n. ivantsov': 'TNNC LLC, RF, Tyumen'}\n",
              "2    {'i.v. goncharov': 'TomskNIPIneft JSC, RF, Tom...\n",
              "3    {'v.yu. ovechkina': 'Paradigm, RF, Moscow', 't...\n",
              "4    {'d.v. efimov': 'BashNIPIneft LLC, RF, Ufa', '...\n",
              "Name: updated_geo, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEgfZ7676xSs"
      },
      "source": [
        "with open(gDrivePath+'a2t.pickle', 'wb') as f:\n",
        "  pickle.dump(dict([(k, np.argmax(v)) for (k, v) in author_to_vec.items()]), f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siYLq81LnUGM"
      },
      "source": [
        "# Train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWfzTgGoq9rQ"
      },
      "source": [
        "def get_geos_encode(df):\n",
        "  updated_geos = df.updated_geo\n",
        "  unique_geos = []\n",
        "  for geos in updated_geos:\n",
        "    for geo in geos.items():\n",
        "      unique_geos.append(normalize_geo(geo[1]))\n",
        "  unique_geos = list(set(unique_geos))\n",
        "  i = 0\n",
        "  geos_encode = {}\n",
        "  for geo in unique_geos:\n",
        "    geos_encode[geo] = i\n",
        "    i += 1\n",
        "  return geos_encode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PU9gyPPWr_qU"
      },
      "source": [
        "G_train = create_graph(df[(df.year >= 2012) & (df.year < 2016)])\n",
        "G_val = create_graph(df[df.year == 2016])\n",
        "G_test = create_graph(df[df.year == 2017])\n",
        "common_authors_val = set(G_train.nodes).intersection(set(G_val.nodes))\n",
        "common_authors_test = set(G_train.nodes).intersection(set(G_test.nodes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8IqQnN-pD29"
      },
      "source": [
        "geos_encode = get_geos_encode(df)\n",
        "\n",
        "def get_data(df, F, geos_encode):\n",
        "  data = []\n",
        "  G = add_sim(create_graph(df), F)\n",
        "  for u, v in combinations(G.nodes(), 2):\n",
        "    if G.has_edge(u, v):\n",
        "      data.append([u, v, geos_encode[G.nodes[u]['geo']], geos_encode[G.nodes[v]['geo']], G[u][v]['sim'], 1])\n",
        "    else:\n",
        "      data.append([u, v, geos_encode[G.nodes[u]['geo']], geos_encode[G.nodes[v]['geo']], SIM(u, v, G, F), 0])\n",
        "  return pd.DataFrame(data, columns=['author_1', 'author_2', 'author_1_a', 'author_2_a',  'sim', 'label'])\n",
        "\n",
        "train_data = get_data(df[df.year < 2016], F, geos_encode)\n",
        "val_data = get_data(df[df.year == 2016], F, geos_encode)\n",
        "test_data = get_data(df[df.year == 2017], F, geos_encode)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBVePWssoxlS"
      },
      "source": [
        "def get_data_without_aff(df, F):\n",
        "  data = []\n",
        "  G = add_sim(create_graph(df), F)\n",
        "  for u, v in combinations(G.nodes(), 2):\n",
        "    if G.has_edge(u, v):\n",
        "      data.append([u, v, G.nodes[u]['geo']==G.nodes[v]['geo'], G[u][v]['sim'], 1])\n",
        "    else:\n",
        "      data.append([u, v, G.nodes[u]['geo']==G.nodes[v]['geo'], SIM(u, v, G, F), 0])\n",
        "  return pd.DataFrame(data, columns=['author_1', 'author_2', 'same_a',  'sim', 'label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5ZjVb7zpkqd"
      },
      "source": [
        "def get_data_with_n_count(df, F):\n",
        "  data = []\n",
        "  G = add_sim(create_graph(df), F)\n",
        "  for u, v in combinations(G.nodes(), 2):\n",
        "    if G.has_edge(u, v):\n",
        "      data.append([u, v, int(G.nodes[u]['geo']==G.nodes[v]['geo']), len(list(nx.common_neighbors(G, u, v))), G[u][v]['sim'], 1])\n",
        "    else:\n",
        "      data.append([u, v, int(G.nodes[u]['geo']==G.nodes[v]['geo']), len(list(nx.common_neighbors(G, u, v))), SIM(u, v, G, F), 0])\n",
        "  return pd.DataFrame(data, columns=['author_1', 'author_2', 'same_a', 'cn',  'sim', 'label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "TmgN479Zqmyd",
        "outputId": "666a557e-5172-43ba-8a7f-1c506a6bd1ef"
      },
      "source": [
        "train_data = get_data_with_n_count(df[df.year < 2016], F)\n",
        "val_data = get_data_with_n_count(df[df.year == 2016], F)\n",
        "test_data = get_data_with_n_count(df[df.year == 2017], F)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author_1</th>\n",
              "      <th>author_2</th>\n",
              "      <th>same_a</th>\n",
              "      <th>cn</th>\n",
              "      <th>sim</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>d.g. nerodenko</td>\n",
              "      <td>k.v. syzrantseva</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.721159</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>d.g. nerodenko</td>\n",
              "      <td>n.n. ivantsov</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.668037</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>d.g. nerodenko</td>\n",
              "      <td>i.v. goncharov</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.385511</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>d.g. nerodenko</td>\n",
              "      <td>n.v. oblasov</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.380196</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>d.g. nerodenko</td>\n",
              "      <td>a.v. smetanin</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.455621</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         author_1          author_2  same_a  cn       sim  label\n",
              "0  d.g. nerodenko  k.v. syzrantseva       1   0  0.721159      1\n",
              "1  d.g. nerodenko     n.n. ivantsov       0   0  0.668037      0\n",
              "2  d.g. nerodenko    i.v. goncharov       0   0  0.385511      0\n",
              "3  d.g. nerodenko      n.v. oblasov       0   0  0.380196      0\n",
              "4  d.g. nerodenko     a.v. smetanin       0   0  0.455621      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zZCP78Er7E8"
      },
      "source": [
        "train_data.to_csv(gDrivePath + 'train_with_n.csv')\n",
        "val_data.to_csv(gDrivePath + 'val_with_n.csv')\n",
        "test_data.to_csv(gDrivePath + 'test_with_n.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BowrKf7PpHhQ",
        "outputId": "b2ad7ccc-a16c-41eb-cc1f-db669ed3cf5a"
      },
      "source": [
        "#train_data_a = get_data_without_aff(df[df.year < 2016], F)\n",
        "#val_data_a = get_data_without_aff(df[df.year == 2016], F)\n",
        "#test_data_a = get_data_without_aff(df[df.year == 2017], F)\n",
        "#test_data_a = test_data_a[test_data_a.author_1.isin(common_authors_test) & test_data_a.author_2.isin(common_authors_test)]\n",
        "#val_data_a = val_data_a[val_data_a.author_1.isin(common_authors_val) & val_data_a.author_2.isin(common_authors_val)]\n",
        "train_data = pd.read_csv(gDrivePath + 'train_a.csv')\n",
        "test_data = pd.read_csv(gDrivePath + 'test_a.csv')\n",
        "val_data = pd.read_csv(gDrivePath + 'val_a.csv')\n",
        "print(test_data.shape, val_data.shape, train_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(56280, 5) (66066, 5) (2355535, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "-ogjVRnfv_LL",
        "outputId": "040dc93d-d1de-4084-877b-a2e86d8604d1"
      },
      "source": [
        "import seaborn as sns\n",
        "train_data_a['dummy'] = 0\n",
        "plt.figure(figsize=(14, 10))\n",
        "plt.xticks(rotation = 90)\n",
        "sns.violinplot(y=\"sim\", x=\"same_a\", hue=\"label\", data=train_data_a, palette=\"pastel\", split=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbcaa0cbbd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kmk-dM1cVay"
      },
      "source": [
        "# train_data_a.to_csv(gDrivePath + 'train_a.csv', index=False)\n",
        "# test_data_a.to_csv(gDrivePath + 'test_a.csv', index=False)\n",
        "# val_data_a.to_csv(gDrivePath + 'val_a.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSo6GeXeKTS_",
        "outputId": "159d8936-cba1-4ba0-aae8-aed25521e5a1"
      },
      "source": [
        "test_data = test_data[test_data.author_1.isin(common_authors_test) & test_data.author_2.isin(common_authors_test)]\n",
        "val_data = val_data[val_data.author_1.isin(common_authors_val) & val_data.author_2.isin(common_authors_val)]\n",
        "print(test_data.shape, val_data.shape, train_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(56280, 5) (66066, 5) (2355535, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HSiRmfeV8AH"
      },
      "source": [
        "train_data.to_csv(gDrivePath + 'train.csv', index=False)\n",
        "test_data.to_csv(gDrivePath + 'test.csv', index=False)\n",
        "val_data.to_csv(gDrivePath + 'val.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skcydchUuqOh"
      },
      "source": [
        "train_data = pd.read_csv(gDrivePath + 'train_a.csv')\n",
        "test_data = pd.read_csv(gDrivePath + 'test_a.csv')\n",
        "val_data = pd.read_csv(gDrivePath + 'val_a.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoeyZtYjfJw6",
        "outputId": "acff9c72-025d-4cff-c678-b4f77638ea29"
      },
      "source": [
        "test_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56280, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKX4qcbsDNie"
      },
      "source": [
        "# Treshold method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ay2fKU7TK2Ti"
      },
      "source": [
        "def calculateSim(G, F):\n",
        "  n = G.number_of_nodes()\n",
        "  d = sparse.lil_matrix((n, n), dtype=float)\n",
        "  for i1, n1 in enumerate(G.nodes):\n",
        "        for i2, n2 in enumerate(G.nodes):\n",
        "            if n1 != n2:\n",
        "                d[i2,i1] = SIM(n1, n2, G, F)\n",
        "  return d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbhlEedAhCFG"
      },
      "source": [
        "sims = calculateSim(G_train, F)\n",
        "df_train_sim = pd.DataFrame(sims.todense(), columns=G_train.nodes, index=G_train.nodes)\n",
        "df_train_sim_ca = df_train_sim.loc[common_authors_val, common_authors_val]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH6VUd8DiYXL"
      },
      "source": [
        "#матрица смежности для тестового набора\n",
        "test_adj = nx.adjacency_matrix(G_val).todense()\n",
        "# то же, только с именами\n",
        "df_test_adj = pd.DataFrame(test_adj, columns=G_val.nodes, index=G_val.nodes)\n",
        "# то же, только для авторов из обоих наборов (train - test)\n",
        "df_test_adj_ca = df_test_adj.loc[common_authors_val, common_authors_val]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6SvBOXXLxxy"
      },
      "source": [
        "#матрица смежности для тестового набора\n",
        "test_adj = nx.adjacency_matrix(G_test).todense()\n",
        "# то же, только с именами\n",
        "df_test_adj = pd.DataFrame(test_adj, columns=G_test.nodes, index=G_test.nodes)\n",
        "# то же, только для авторов из обоих наборов (train - test)\n",
        "df_test_adj_ca = df_test_adj.loc[common_authors_test, common_authors_test]\n",
        "df_train_sim_ca = df_train_sim.loc[common_authors_test, common_authors_test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t624G4zSL4dS",
        "outputId": "9083ad4a-13b2-4e69-f9de-b1f550ba32cd"
      },
      "source": [
        "#Сколько должно быть общих соседей чтобы сказать что между вершинами будет связь?\n",
        "threshold = 0.791\n",
        "#Матрица смежности для связей которые могут быть в будущем\n",
        "mask = (df_train_sim_ca > threshold).astype(int)\n",
        "#сколько ребер предсказано верно\n",
        "\n",
        "#точность предсказания связей графа\n",
        "precision = precision_score(df_test_adj_ca.values.flatten(), mask.values.flatten())\n",
        "recall = recall_score(df_test_adj_ca.values.flatten(), mask.values.flatten())\n",
        "f3 = 10 * recall * precision / (9 * precision + recall)\n",
        "print('Precision ' + str(precision))\n",
        "print('Recall ' + str(recall))\n",
        "print('F3 ' + str(f3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision 0.13811007268951195\n",
            "Recall 0.5076335877862596\n",
            "F3 0.40048178259560374\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCC_i0pma205"
      },
      "source": [
        "# TM + affiliations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nw6cuYHIIp5h"
      },
      "source": [
        "X_train = train_data.drop('author_1', axis=1).drop('author_2', axis=1).drop('label', axis=1)\n",
        "y_train = train_data['label']\n",
        "X_test = test_data.drop('author_1', axis=1).drop('author_2', axis=1).drop('label', axis=1)\n",
        "y_test = test_data['label']\n",
        "X_val = val_data.drop('author_1', axis=1).drop('author_2', axis=1).drop('label', axis=1)\n",
        "y_val = val_data['label']\n",
        "cat_feat = ['same_a']\n",
        "test = cgb.Pool(data=X_test, label=y_test, cat_features=cat_feat)\n",
        "val = cgb.Pool(data=X_val, label=y_val, cat_features=cat_feat)\n",
        "train = cgb.Pool(data=X_train, label=y_train, cat_features=cat_feat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "86nrdpE7bRWD",
        "outputId": "ed7d3bbb-00fb-4f83-f95f-85380c38db5b"
      },
      "source": [
        "def score(params):\n",
        "  model = cgb.CatBoostClassifier(**params, task_type=\"GPU\", logging_level='Silent')\n",
        "  model.fit(train, eval_set=val)\n",
        "  metrics = model.eval_metrics(val, ['F1:use_weights=false'])\n",
        "\n",
        "  return {'loss': -metrics['F1:use_weights=false'][-1], 'status': STATUS_OK}\n",
        "\n",
        "space = {\n",
        "    'loss_function': 'Logloss',\n",
        "    'eval_metric': 'F1:use_weights=false',\n",
        "    'iterations': hp.choice('iterations', np.arange(50, 500, 50)),\n",
        "    'learning_rate': hp.uniform('learning_rate', 0.1, 1),\n",
        "    'random_seed': 42,\n",
        "    'l2_leaf_reg': hp.uniform('l2_leaf_reg', 0, 20),\n",
        "    'depth': hp.choice('depth', np.arange(3, 16, 1)),\n",
        "    'min_data_in_leaf': hp.uniform('min_data_in_leaf', 0, 10),\n",
        "    #'max_leaves': hp.choice('max_leaves', np.arange(20, 64, 1)),\n",
        "    'auto_class_weights': hp.choice('auto_class_weights', ['Balanced', 'SqrtBalanced']),\n",
        "          }\n",
        "\n",
        "def optimize(trials, space):\n",
        "  best = fmin(score, space, algo = tpe.suggest, max_evals = 400)\n",
        "  return best\n",
        "\n",
        "trials = Trials()\n",
        "best_params = optimize(trials, space)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 47/400 [14:36<1:49:44, 18.65s/it, best loss: -0.4305210918114144]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-a7b2f5f31741>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-62-a7b2f5f31741>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(trials, space)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    405\u001b[0m                     show_progressbar=show_progressbar)\n\u001b[1;32m    406\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    225\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                         \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    842\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 844\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-62-a7b2f5f31741>\u001b[0m in \u001b[0;36mscore\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"GPU\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Silent'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'F1:use_weights=false'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   4539\u001b[0m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[1;32m   4540\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4541\u001b[0;31m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\n\u001b[0m\u001b[1;32m   4542\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m                 \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"init_model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m             )\n\u001b[1;32m   1925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1366\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1367\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmdcEPMq4VX_"
      },
      "source": [
        "# Классификатор (CatBoost)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkY8TE53Hked"
      },
      "source": [
        "model = cgb.CatBoostClassifier(loss_function='Logloss',\n",
        "                               eval_metric='F1:use_weights=false',\n",
        "                               random_seed=42,\n",
        "                               auto_class_weights='SqrtBalanced',\n",
        "                               iterations = 70,\n",
        "                               logging_level='Verbose')\n",
        "model.fit(train, eval_set=val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBE7h_a6w7oY"
      },
      "source": [
        "def findBestTresholdForF1(probs, y):\n",
        "  best_f1 = 0\n",
        "  treshold = 0\n",
        "  for prob in set(probs):\n",
        "    preds = (probs > prob).astype(int)\n",
        "    f1 = f1_score(y, preds)\n",
        "    if f1 > best_f1:\n",
        "      best_f1 = f1\n",
        "      treshold = prob\n",
        "  return best_f1, treshold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gUx_siYHkee",
        "outputId": "af6bf055-54b9-45fd-c293-7e3f512dec64"
      },
      "source": [
        "probs = model.predict_proba(test)\n",
        "f1, tresh = findBestTresholdForF1(probs[:, 1], test.get_label())\n",
        "preds = (probs[:, 1] > tresh).astype(int)\n",
        "f1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3784355179704017"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xS2IBTfkPKh5"
      },
      "source": [
        "model.eval_metrics(test, ['PRAUC:use_weights=false', 'F1:use_weights=false', 'AUC:use_weights=false', 'Precision:use_weights=false', 'Recall:use_weights=false'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXWlN2e4tFN_",
        "outputId": "809378a6-7e82-45c4-f980-18f257f957b3"
      },
      "source": [
        "test.get_label().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29127"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MY8m3-NxrNjE",
        "outputId": "cae8dbbf-3db8-4b88-bc40-d46b3c9bcde5"
      },
      "source": [
        "cgb.utils.get_confusion_matrix(model, test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  147.,   129.],\n",
              "       [  724., 28403.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhz9Oj7MHkeg"
      },
      "source": [
        "metrics = model.eval_metrics(val, ['AUC', 'Precision', 'BalancedAccuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jwx9SfONHkeg",
        "outputId": "f72a8660-ac9f-45a7-a945-db442f950cba"
      },
      "source": [
        "def predict(model, train, test):\n",
        "  roc_curve_values = get_roc_curve(model, train)\n",
        "  boundary = select_threshold(model, curve=roc_curve_values, FPR=0.9)\n",
        "  print(boundary)\n",
        "  proba = model.predict_proba(test)\n",
        "  predicted = (proba[:, 1] >  boundary).astype(int)\n",
        "  return predicted, proba[:, 1]\n",
        "\n",
        "predicted, proba = predict(model, train, val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.048717640047834763\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDe9PW1gudRJ",
        "outputId": "dbb12f5d-90cf-4818-ec90-511f0cc69f28"
      },
      "source": [
        "predicted = -1 * predicted + 1\n",
        "actual = -1 * val.get_label() + 1\n",
        "tp = (predicted * actual).sum()\n",
        "print(roc_auc_score(actual, 1 - proba), tp / predicted.sum())\n",
        "print(predicted.sum(), tp.sum())\n",
        "print(actual.sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9116688423786579 0.7111111111111111\n",
            "45 32\n",
            "353\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViGgFsfzHkeh"
      },
      "source": [
        "plt.figure(figsize = (14,10))\n",
        "plt.plot(np.arange(len(metrics['Precision'])), metrics['Precision'], label = 'Pr')\n",
        "plt.plot(np.arange(len(metrics['AUC'])), metrics['AUC'], label = 'AUC')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0ybv3a6sM0D"
      },
      "source": [
        "plt.figure(figsize = (14,10))\n",
        "plt.plot(np.arange(len(metrics['Precision'])), metrics['Precision'], label = 'Pr')\n",
        "plt.plot(np.arange(len(metrics['AUC'])), metrics['AUC'], label = 'AUC')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CPty-Agc94W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4igS6l8dAoQ"
      },
      "source": [
        "# Classifier (Desision tree)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQFu9DybdFim"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import export_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iG5Zx-MFebXR",
        "outputId": "a513708f-b783-4f52-d749-6c8b3fcbe7c1"
      },
      "source": [
        "clf = DecisionTreeClassifier(random_state=42, class_weight = 'balanced')\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced', criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=42, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylOTSzTtHye5",
        "outputId": "82bd73c1-3c23-40e6-97b5-036561e5b97b"
      },
      "source": [
        "train_data[train_data.label == 0].shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2349620"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Dz6RTltBILx",
        "outputId": "8c1225ea-34aa-48e3-eabb-cb46f276eec9"
      },
      "source": [
        "probs = clf.predict_proba(X_test)\n",
        "f1, tresh = findBestTresholdForF1(probs[:, 1], y_test)\n",
        "preds = (probs[:, 1] > tresh).astype(int)\n",
        "roc_auc_score(y_test, probs[:, 1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6300640495200188"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c79OdZPe_AH",
        "outputId": "3c74238f-d765-40d6-c8f3-a34481e88302"
      },
      "source": [
        "classification_report(y_val, clf.predict(X_val), output_dict=True)['1']['f1-score']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3677342823250297"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbVdWHHyfnUE"
      },
      "source": [
        "def score(params):\n",
        "  clf = DecisionTreeClassifier(random_state=42, class_weight = 'balanced')\n",
        "  clf.fit(X_train, y_train)\n",
        "  f1 = classification_report(y_val, clf.predict(X_val), output_dict=True)['1']['f1-score']\n",
        "  return {'loss': -f1, 'status': STATUS_OK}\n",
        "\n",
        "space = {\n",
        "    'max_depth': hp.choice('max_depth', np.arange(3, 16, 1)),\n",
        "    'min_samples_split': hp.choice('min_samples_split', np.arange(2, 5, 1)),\n",
        "    'min_samples_leaf': hp.choice('min_samples_leaf', np.arange(1, 5, 1)),\n",
        "    'max_features': hp.choice('max_features', [1, 2]),\n",
        "    'max_leaf_nodes': hp.choice('max_leaf_nodes', range(5, 64, 5)),\n",
        "    'ccp_alpha': hp.uniform('ccp_alpha', 0, 10)\n",
        "          }\n",
        "\n",
        "def optimize(trials, space):\n",
        "  best = fmin(score, space, algo = tpe.suggest, max_evals = 1000)\n",
        "  return best\n",
        "\n",
        "trials = Trials()\n",
        "best_params = optimize(trials, space)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by0NilQOjjTN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}