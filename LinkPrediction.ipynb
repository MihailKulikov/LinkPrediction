{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_xPt3FwiyAf",
        "outputId": "26c4e841-1feb-4307-a808-93fff709c0d3"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEe5rH39nZSd"
      },
      "outputs": [],
      "source": [
        "gDrivePath = \"/content/drive/My Drive/Link prediction/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBaAAgyvTVCm",
        "outputId": "4f1c1eae-9225-42cc-e2c9-a664546bc9fc"
      },
      "outputs": [],
      "source": [
        "!pip install -q pymorphy2\n",
        "!pip install -q bigartm10\n",
        "!pip install -q catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrFP7rgXpxRO",
        "outputId": "10dd84a8-079e-4bde-c78a-dce6547c182b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "import json, os, re\n",
        "from tqdm import tqdm as tq\n",
        "import pymorphy2\n",
        "import artm\n",
        "import numpy as np\n",
        "from scipy import spatial\n",
        "import networkx as nx\n",
        "from itertools import combinations\n",
        "import catboost as cgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "import scipy\n",
        "import matplotlib.pyplot   as plt\n",
        "from scipy import sparse\n",
        "from sklearn.metrics import roc_auc_score, precision_score, balanced_accuracy_score\n",
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, space_eval\n",
        "from catboost.utils import get_roc_curve, select_threshold\n",
        "from sklearn.metrics import balanced_accuracy_score, precision_recall_curve, auc, recall_score, f1_score, precision_score, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKw8QRsYISvu"
      },
      "source": [
        "## Чистим текст"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWwa-HUgsuZb"
      },
      "outputs": [],
      "source": [
        "def flatten(l):\n",
        "    return [item for sublist in l for item in sublist]\n",
        "\n",
        "def cleanNames(names_list):\n",
        "    expr = r'[А-ЯЁ]\\.[А-ЯЁ]\\. [А-ЯЁ][а-яё]*|[А-ЯЁ][а-яё]* [А-ЯЁ]\\.[А-ЯЁ]\\.'\n",
        "    filt_list = []\n",
        "    for name in names_list:\n",
        "        filt_list.append([x for x in re.findall(expr, name) if x != []])\n",
        "    filt_list2 = []\n",
        "    for l in flatten(filt_list):\n",
        "        x1, x2 = l.split(' ')\n",
        "        if x1.count('.') == 2:\n",
        "            filt_list2.append(l)\n",
        "        else:\n",
        "            filt_list2.append(' '.join([x2,x1]))\n",
        "    return filt_list2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GF6qheustGVN"
      },
      "outputs": [],
      "source": [
        "json_files = os.listdir(gDrivePath + \"geofix/\")\n",
        "json_files.sort()\n",
        "df = pd.DataFrame(columns=['authors_raw', 'year', 'geo', 'geo_full', 'text'])\n",
        "\n",
        "for index, js in enumerate(json_files):\n",
        "    with open(os.path.join(gDrivePath + \"geofix/\", js)) as json_file:\n",
        "        json_text = json.load(json_file)\n",
        "        authors = json_text['authors_cleaned']\n",
        "        year = json_text['year']\n",
        "        geo = json_text['geo_tags']\n",
        "        geo_full = json_text['geo_tags_full']\n",
        "        text = json_text['text']\n",
        "        df.loc[index] = [authors, year, geo, geo_full, text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdrZ-N9wf6S7"
      },
      "outputs": [],
      "source": [
        "df['authors'] = df['authors_raw'].apply(cleanNames)\n",
        "df['year'] = df['year'].astype(int)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXoH18Y9VlZR"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(gDrivePath + 'initial_data_2015.csv')\n",
        "df.updated_geo = df.updated_geo.apply(eval)\n",
        "df.geo_full = df.geo_full.apply(eval)\n",
        "#df.to_csv(gDrivePath + 'initial_data.csv')\n",
        "#df.to_csv(gDrivePath + 'initial_data_2015.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEAz49UGnJBY"
      },
      "outputs": [],
      "source": [
        "F = pd.read_csv(gDrivePath + 'F_2015.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V12OR28pg4Zg",
        "outputId": "3ba1ea2d-e719-459c-89e2-3287c26dc929"
      },
      "outputs": [],
      "source": [
        "df[df.year==2016].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mf0ydcs_LX_z"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def set_geos(geos):\n",
        "  all_geos = geos.items()\n",
        "  authors = list(geos.keys())\n",
        "  geo_to_count = Counter([geo[1] for geo in all_geos if isinstance(geo[1], str)])\n",
        "  if len(geo_to_count) == 0:\n",
        "    for author in authors:\n",
        "      geos[author] = ''\n",
        "    return geos\n",
        "  frequent_geo = max(geo_to_count.items(), key = lambda kvp: kvp[1])[0]\n",
        "  for author in authors:\n",
        "    if not isinstance(geos[author], str):\n",
        "      geos[author] = frequent_geo\n",
        "  return geos\n",
        "\n",
        "df['updated_geo'] = df.geo_full.apply(set_geos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rl9qpJoACigk"
      },
      "outputs": [],
      "source": [
        "def remove_useless(row):\n",
        "  text = row['text']\n",
        "  index = row['index']\n",
        "  kw_index_en = text.find(\"Key words\")\n",
        "  kw_index_ru = text.find(\"Ключевые слова\")\n",
        "  email_index = text.find(\"E-mail\")\n",
        "  reference_index_en = text.find(\"Reference\")\n",
        "  reference_index_ru = text.find(\"Спиоск литературы\")\n",
        "  begin = 0\n",
        "  if kw_index_en > kw_index_ru:\n",
        "    begin = kw_index_en + len(\"key words\")\n",
        "  elif kw_index_en < kw_index_ru:\n",
        "    begin = kw_index_ru + len(\"Ключевые слова\")\n",
        "  end = len(text)\n",
        "  if reference_index_en < reference_index_ru:\n",
        "    end = reference_index_en\n",
        "  else:\n",
        "    end = reference_index_ru\n",
        "  center = text[begin:end]\n",
        "  words = [morph.parse(x.lower().replace(u'ё', u'е'))[0].normal_form\n",
        "           for x in re.findall(r'[ЁА-Яа-яё]+', center)\n",
        "           if len(x) > 2 and x != \"при\" and x != \"для\" and x != \"быть\" and x != \"что\" and x != \"рис\" and x != 'это' and x != 'где']\n",
        "  return str(index) + \" |words \" + \" \".join(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1xCRfTGF98b",
        "outputId": "e57b35f2-71f9-44c2-c9d7-4c07644361a7"
      },
      "outputs": [],
      "source": [
        "morph = pymorphy2.MorphAnalyzer()\n",
        "vw = df.reset_index().apply(remove_useless, axis=1)\n",
        "vw.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q68J3c1dPUqM"
      },
      "outputs": [],
      "source": [
        "# with open(gDrivePath + 'vw_rp_2015.txt', 'w') as fout:\n",
        "#     for line in vw:\n",
        "#         fout.write(line + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDV_rRtPWTi8"
      },
      "source": [
        "# Строим тематические модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Td8CwU5ZWOWV"
      },
      "outputs": [],
      "source": [
        "# batch_vectorizer = artm.BatchVectorizer(data_path=gDrivePath + 'vw_rp_2015.txt', data_format='vowpal_wabbit', collection_name='vw', target_folder=gDrivePath + 'batches_rp_2015')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Tz6t2vjWOQd"
      },
      "outputs": [],
      "source": [
        "batch_vectorizer = artm.BatchVectorizer(data_path=gDrivePath + 'batches_rp_2015', data_format = 'batches')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfQ2IqmMXYFS",
        "outputId": "88e27cb8-fa9d-4678-d1a0-2a0965c2b241"
      },
      "outputs": [],
      "source": [
        "dictionary = artm.Dictionary()\n",
        "dictionary.gather(data_path=batch_vectorizer.data_path)\n",
        "dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olNoWOB6XYBC"
      },
      "outputs": [],
      "source": [
        "def print_topic_top_words(model, metric):\n",
        "    for topic_name in model.topic_names:\n",
        "      print(topic_name + ': '),\n",
        "      try:\n",
        "          print(\", \".join(model.score_tracker[metric].last_tokens[topic_name]))\n",
        "      except:\n",
        "          print(\"Not enough unigrams in a topic\")\n",
        "          print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFUicKXl4d4z"
      },
      "source": [
        "## PLSA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqyrkMBHXYL8"
      },
      "outputs": [],
      "source": [
        "model_plsa = artm.ARTM(topic_names=['topic_{}'.format(i) for i in range(10)],\n",
        "                       scores=[artm.PerplexityScore(name='PerplexityScore',\n",
        "                                                    dictionary=dictionary)],\n",
        "                       cache_theta=True, reuse_theta=True, theta_columns_naming='title')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGiZEciBXYKr"
      },
      "outputs": [],
      "source": [
        "model_plsa.scores.add(artm.SparsityPhiScore(name='SparsityPhiScoreP', class_id='words', eps=1e-5))\n",
        "model_plsa.scores.add(artm.SparsityThetaScore(name='SparsityThetaScoreP', eps=1e-5))\n",
        "model_plsa.scores.add(artm.TopTokensScore(name='TopTokensScoreP', num_tokens=10, class_id='words'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nf_kJg79XYJh"
      },
      "outputs": [],
      "source": [
        "model_plsa.initialize(dictionary=dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsfOhXhzXYCX",
        "outputId": "b29d45b5-c9ce-406b-fbfe-458447863024"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "model_plsa.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BIsWy5v0lGI",
        "outputId": "1baac6a2-5bbd-4c3b-f551-786c22819d9a"
      },
      "outputs": [],
      "source": [
        "print_topic_top_words(model_plsa, 'TopTokensScoreP')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBckL4TQ6V6o",
        "outputId": "59643e71-0d38-4256-e9a5-474d4f7f1b8d"
      },
      "outputs": [],
      "source": [
        "print(model_plsa.score_tracker['SparsityPhiScoreP'].last_value)\n",
        "print(model_plsa.score_tracker['SparsityThetaScoreP'].last_value)\n",
        "theta0 = model_plsa.get_theta()\n",
        "print('Num zeros col in theta: ', sum([(theta0[i] == 0).all() for i in theta0.columns]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSo5vK34kxfa"
      },
      "outputs": [],
      "source": [
        "# F = model_plsa.get_theta()\n",
        "# F.to_csv(gDrivePath+f'/data/plsa_theta.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq0_BMei4pKl"
      },
      "source": [
        "## LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sB0xN6tSjUAo"
      },
      "outputs": [],
      "source": [
        "model_lda = artm.ARTM(topic_names=['topic_{}'.format(i) for i in range(14)],\n",
        "                       scores=[artm.PerplexityScore(name='PerplexityScore',\n",
        "                                                    dictionary=dictionary)],\n",
        "                       regularizers=[artm.SmoothSparseThetaRegularizer(name='SparseTheta', tau=-0.7),\n",
        "                                     artm.SmoothSparsePhiRegularizer(name='SparsePhi', tau=-0.1)],\n",
        "                       cache_theta=True, reuse_theta=True, theta_columns_naming='title')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMnspgCCmZfY"
      },
      "outputs": [],
      "source": [
        "model_lda.scores.add(artm.SparsityPhiScore(name='SparsityPhiScoreL', class_id='words', eps=1e-5))\n",
        "model_lda.scores.add(artm.SparsityThetaScore(name='SparsityThetaScoreL', eps=1e-5))\n",
        "model_lda.scores.add(artm.TopTokensScore(name='TopTokensScoreL', num_tokens=15, class_id='words'))\n",
        "model_lda.initialize(dictionary=dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kN3D7eHzmd9r",
        "outputId": "b2bc5903-e0e5-4b4e-a810-f59f4ece52dc"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "model_lda.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ha7Lx_eRuevm",
        "outputId": "1f03cce4-97dc-4198-c078-ef1aeb8a9efe"
      },
      "outputs": [],
      "source": [
        "print(model_lda.score_tracker['SparsityPhiScoreL'].last_value)\n",
        "print(model_lda.score_tracker['SparsityThetaScoreL'].last_value)\n",
        "theta0 = model_lda.get_theta()\n",
        "print('Num zeros col in theta: ', sum([(theta0[i] == 0).all() for i in theta0.columns]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTAVeiZZuV4R"
      },
      "outputs": [],
      "source": [
        "print_topic_top_words(model_lda, 'TopTokensScoreL')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sE8wY8sgmtnY"
      },
      "outputs": [],
      "source": [
        "# F = model_lda.get_theta()\n",
        "# F.to_csv(gDrivePath+'/data/lda_theta.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0vEZF6v4lbi"
      },
      "source": [
        "## ARTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6g32ZmP6Zih"
      },
      "outputs": [],
      "source": [
        "model_artm = artm.ARTM(topic_names=['topic_{}'.format(i) for i in range(9)],\n",
        "                       scores=[artm.PerplexityScore(name='PerplexityScore',\n",
        "                                                    dictionary=dictionary)],\n",
        "                       regularizers=[artm.SmoothSparseThetaRegularizer(name='SparseTheta', tau=-0.5),\n",
        "                                     artm.SmoothSparsePhiRegularizer(name='SparsePhi', tau=-0.001)],\n",
        "                       cache_theta=True, reuse_theta=True, theta_columns_naming='title')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHRKzgZ30Lxt"
      },
      "outputs": [],
      "source": [
        "model_artm.regularizers.add(artm.DecorrelatorPhiRegularizer(name='DecorrelatorPhi', tau=-50e3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VXFagbb0Lun"
      },
      "outputs": [],
      "source": [
        "model_artm.scores.add(artm.SparsityPhiScore(name='SparsityPhiScoreA', class_id='words', eps=1e-5))\n",
        "model_artm.scores.add(artm.SparsityThetaScore(name='SparsityThetaScoreA', eps=1e-5))\n",
        "model_artm.scores.add(artm.TopTokensScore(name='TopTokensScoreA', num_tokens=15, class_id='words'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4O4gFaM0LsL"
      },
      "outputs": [],
      "source": [
        "model_artm.initialize(dictionary=dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "GGFwT1pZ0RPm",
        "outputId": "94c7dc2b-c29f-49b5-87c6-1cbcaf2393bb"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "model_artm.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UuckHpn0RhL"
      },
      "outputs": [],
      "source": [
        "print(model_artm.score_tracker['SparsityPhiScoreA'].last_value)\n",
        "print(model_artm.score_tracker['SparsityThetaScoreA'].last_value)\n",
        "theta0 = model_artm.get_theta()\n",
        "print('Num zeros col in theta: ', sum([(theta0[i] == 0).all() for i in theta0.columns]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YHangAA0RZ2"
      },
      "outputs": [],
      "source": [
        "print_topic_top_words(model_artm, 'TopTokensScoreA')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zp6dCmaQjmO_"
      },
      "outputs": [],
      "source": [
        "F = model_artm.get_theta()\n",
        "# F.to_csv(gDrivePath+f'/data/artm_theta.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JameXoMNVFc"
      },
      "source": [
        "## Иерархическая"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShYFlPRH3ref"
      },
      "outputs": [],
      "source": [
        "hier = artm.hARTM(scores=[artm.PerplexityScore(name='PerplexityScore', dictionary=dictionary)],\n",
        "                  cache_theta=True, reuse_theta=True, theta_columns_naming='title')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVQzTUJodGiG",
        "outputId": "49366f3a-e314-4929-e7cf-6780fabefcc5"
      },
      "outputs": [],
      "source": [
        "level0 = hier.add_level(num_topics=9)\n",
        "level0.initialize(dictionary)\n",
        "level0.regularizers.add(artm.DecorrelatorPhiRegularizer(name='DecorrelatorPhi0', tau=5e3))\n",
        "level0.regularizers.add(artm.SmoothSparseThetaRegularizer(name='SparseTheta', tau=-0.5))\n",
        "level0.regularizers.add(artm.SmoothSparsePhiRegularizer(name='SparsePhi', tau=-0.1))\n",
        "\n",
        "level0.scores.add(artm.SparsityPhiScore(name='SparsityPhiScore0', class_id='words', eps=1e-5))\n",
        "level0.scores.add(artm.SparsityThetaScore(name='SparsityThetaScore0', eps=1e-5))\n",
        "%time level0.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrO95jm9cwKV",
        "outputId": "a2639e72-8f5a-4af9-a8b9-dec279ee68db"
      },
      "outputs": [],
      "source": [
        "print('level0')\n",
        "print('SparsityPhi: ', level0.score_tracker['SparsityPhiScore0'].last_value)\n",
        "print('SparsityTheta: ', level0.score_tracker['SparsityThetaScore0'].last_value)\n",
        "theta0 = level0.get_theta()\n",
        "print('Num zeros col in theta: ', sum([(theta0[i] == 0).all() for i in theta0.columns]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVi3G5sBdlFQ"
      },
      "outputs": [],
      "source": [
        "level1 = hier.add_level(num_topics=50, topic_names=['child_topic_' + str(i) for i in range(25)], parent_level_weight=1)\n",
        "level1.scores.add(artm.SparsityPhiScore(name='SparsityPhiScore1', class_id='words', eps=1e-5))\n",
        "level1.scores.add(artm.SparsityThetaScore(name='SparsityThetaScore1', eps=1e-5))\n",
        "level1.scores.add(artm.TopTokensScore(name='TopTokensScore1', num_tokens=15, class_id='words'))\n",
        "level1.regularizers.add(artm.HierarchySparsingThetaRegularizer(name=\"HierSp\", tau=2),overwrite=True)\n",
        "level1.regularizers.add(artm.SmoothSparsePhiRegularizer(name='SparsePhi', tau=-0.1),overwrite=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpJIGbm9gNaX",
        "outputId": "0fb950ea-1569-4909-cf4d-bb124c293704"
      },
      "outputs": [],
      "source": [
        "level1.initialize(dictionary)\n",
        "level1.regularizers.add(artm.SmoothSparseThetaRegularizer(name='SparseTheta', tau=-0.01),overwrite=True)\n",
        "level1.regularizers.add(artm.DecorrelatorPhiRegularizer(name='DecorrelatorPhi1', tau=15e4),overwrite=True)\n",
        "%time level1.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBxBWR5_ZIqy",
        "outputId": "75f99f86-abe0-4d69-ae65-d21b2e074586"
      },
      "outputs": [],
      "source": [
        "print('level1')\n",
        "print('SparsityPhi: ', level1.score_tracker['SparsityPhiScore1'].last_value)\n",
        "print('SparsityTheta: ', level1.score_tracker['SparsityThetaScore1'].last_value)\n",
        "theta1 = level1.get_theta()\n",
        "print('Num zeros col in theta: ',sum([(theta1[i] == 0).all() for i in theta1.columns]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZF1ctJyRdfNV",
        "outputId": "e80cd8a9-f4dc-486b-a1a7-1bab71e93708"
      },
      "outputs": [],
      "source": [
        "print_topic_top_words(level1, 'TopTokensScore1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNlKf8vFL6aP"
      },
      "source": [
        "## Визуализатор"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "g9-5pw2epBst",
        "outputId": "8adf6030-4380-464b-effa-d7e08532ebba"
      },
      "outputs": [],
      "source": [
        "theta_T = level1.get_theta().T\n",
        "phi_T = level1.get_phi().T\n",
        "phi_T.columns = phi_T.columns.to_series().apply(lambda name: name[1])\n",
        "phi_T.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvDq5T8lzxBI",
        "outputId": "89f756ae-5ec0-42c2-a7dd-611630d6a636"
      },
      "outputs": [],
      "source": [
        "!pip install -q pyldavis\n",
        "import pyLDAvis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6IfGROYVAM8"
      },
      "outputs": [],
      "source": [
        "doc_lengths = []\n",
        "with open(gDrivePath + 'vw_rp_2015.txt', 'r') as file:\n",
        "    for i in range(1459):\n",
        "        words = file.readline().split()[2:]\n",
        "        doc_lengths.append(len(words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NN4ZVzkz0zV4",
        "outputId": "32cb3351-0a3e-41f3-ebe4-7950a744ceaf"
      },
      "outputs": [],
      "source": [
        "html = pyLDAvis.prepare(topic_term_dists = phi_T.values, \n",
        "                        doc_topic_dists = theta_T.values, \n",
        "                        doc_lengths = doc_lengths,\n",
        "                        vocab = phi_T.columns,\n",
        "                        term_frequency = dictionary._master.get_dictionary(dictionary._name).token_tf,\n",
        "                        R = 15)\n",
        "\n",
        "pyLDAvis.save_html(html, 'hARTM.html')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "ek-7vvroOOSK",
        "outputId": "f34c1db9-b383-48a8-99f3-0523e1014be8"
      },
      "outputs": [],
      "source": [
        "F = level1.get_theta()\n",
        "F.to_csv(gDrivePath + 'F_2015.csv', index=False)\n",
        "F.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntubjMbxHSXh"
      },
      "outputs": [],
      "source": [
        "# theta0.to_csv(gDrivePath+'/data/hier_theta_0.csv')\n",
        "# theta1.to_csv(gDrivePath+'/data/hier_theta_1.csv')\n",
        "# psi = level1.get_psi()\n",
        "# psi.to_csv(gDrivePath+'/data/hier_psi_1.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu5miS8afnV4",
        "outputId": "68858299-13f1-48f1-d7ae-d6b1d26490c8"
      },
      "outputs": [],
      "source": [
        "# with open(gDrivePath+'/data/phi1.batch', 'w') as f:\n",
        "#     f.write('phi1.batch')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn6MfCKsHZ0m"
      },
      "source": [
        "# Авторы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hqou8SE0VHDk"
      },
      "outputs": [],
      "source": [
        "def normalize_geo(geo):\n",
        "  geo = re.sub(r'[%s]' % re.escape(r\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_«»“”’*…/_.\\\\`{|}~\"\"\"), '', geo).strip()\n",
        "  words = geo.split()\n",
        "  if len(words) == 0:\n",
        "    return \"\"\n",
        "  if words[0] == \"Institute\":\n",
        "    return \" \".join(words[:3])\n",
        "  elif words[0] == \"et\" or words[0] == \"at\":\n",
        "    return \"\"\n",
        "  else:\n",
        "    return \" \".join(words[:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZxdFaEz28oF"
      },
      "outputs": [],
      "source": [
        "def create_graph(frame):\n",
        "    G = nx.Graph()\n",
        "    for i, row in frame.iterrows():\n",
        "        authors = list(row['updated_geo'].items())\n",
        "        if len(authors) == 1:\n",
        "            try:\n",
        "              geo = normalize_geo(authors[0][1])\n",
        "            except AttributeError:\n",
        "              geo = ''\n",
        "            G.add_node(authors[0][0], geo = geo)\n",
        "        else:\n",
        "            for auth1, auth2 in combinations(authors, 2):\n",
        "                try:\n",
        "                    geo1 = normalize_geo(auth1[1])\n",
        "                except AttributeError:\n",
        "                    geo1 = ''\n",
        "                try:\n",
        "                    geo2 = normalize_geo(auth2[1])\n",
        "                except AttributeError:\n",
        "                    geo2 = ''\n",
        "                    \n",
        "                G.add_node(auth1[0], geo=geo1)\n",
        "                G.add_node(auth2[0], geo=geo2)\n",
        "                G.add_edge(auth1[0], auth2[0])\n",
        "    return G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjCGg_PjfKBY"
      },
      "outputs": [],
      "source": [
        "paper_to_authors = df.geo_full.apply(lambda geos: list(geos.keys())).to_dict()\n",
        "unique_authors = []\n",
        "for authors in df.geo_full.apply(lambda geos: geos.keys()).tolist():\n",
        "  unique_authors += authors\n",
        "unique_authors = list(set(unique_authors))\n",
        "author_to_papers = dict.fromkeys(unique_authors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPDPdlg3ubi_"
      },
      "outputs": [],
      "source": [
        "for paper in F.columns:\n",
        "  for author in paper_to_authors[int(paper)]:\n",
        "    if author_to_papers[author] is None:\n",
        "      author_to_papers[author] = [F[paper].tolist()]\n",
        "    else:\n",
        "      author_to_papers[author].append(F[paper].tolist())\n",
        "for author in author_to_papers.keys():\n",
        "  author_to_papers[author] = np.array(author_to_papers[author])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBkNozWMfIar"
      },
      "outputs": [],
      "source": [
        "author_to_vec = dict()\n",
        "for author in author_to_papers.keys():\n",
        "  author_to_vec[author] = np.mean(author_to_papers[author], axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVrMEwBm16RJ"
      },
      "outputs": [],
      "source": [
        "def S(u_vec, v_vec):\n",
        "  return 1 / np.exp(spatial.distance.cosine(u_vec, v_vec))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hU5kso0l82K0"
      },
      "outputs": [],
      "source": [
        "def SIM(u_name, v_name, G, F):\n",
        "  s = S(author_to_vec[u_name], author_to_vec[v_name])\n",
        "  neighbors = nx.common_neighbors(G, u_name, v_name)\n",
        "  norm = 0\n",
        "  sum = 0\n",
        "  for neighbor in neighbors:\n",
        "    norm += 1\n",
        "    uz_papers = np.array([F[str(paper)] for paper in paper_to_authors.keys()\n",
        "                    if neighbor in paper_to_authors[paper]\n",
        "                    and u_name in paper_to_authors[paper]])\n",
        "    vz_papers = np.array([F[str(paper)] for paper in paper_to_authors.keys()\n",
        "                    if neighbor in paper_to_authors[paper]\n",
        "                    and v_name in paper_to_authors[paper]])\n",
        "    x_uz = np.mean(uz_papers, axis=0)\n",
        "    x_vz = np.mean(vz_papers, axis=0)\n",
        "    sum += S(x_uz, x_vz)\n",
        "  if sum == 0:\n",
        "    return s\n",
        "  else:\n",
        "    return s / norm * sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpEeSqW4JX5I"
      },
      "outputs": [],
      "source": [
        "def add_sim(G, F):\n",
        "  for (u, v) in G.edges():\n",
        "    G.add_edge(u, v, sim = SIM(u, v, G, F))\n",
        "  return G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2lSBFZlc98X",
        "outputId": "f46579c6-f640-4b2f-9165-bfc4ea1c1933"
      },
      "outputs": [],
      "source": [
        "df.updated_geo.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEgfZ7676xSs"
      },
      "outputs": [],
      "source": [
        "with open(gDrivePath+'a2t.pickle', 'wb') as f:\n",
        "  pickle.dump(dict([(k, np.argmax(v)) for (k, v) in author_to_vec.items()]), f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siYLq81LnUGM"
      },
      "source": [
        "# Train test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWfzTgGoq9rQ"
      },
      "outputs": [],
      "source": [
        "def get_geos_encode(df):\n",
        "  updated_geos = df.updated_geo\n",
        "  unique_geos = []\n",
        "  for geos in updated_geos:\n",
        "    for geo in geos.items():\n",
        "      unique_geos.append(normalize_geo(geo[1]))\n",
        "  unique_geos = list(set(unique_geos))\n",
        "  i = 0\n",
        "  geos_encode = {}\n",
        "  for geo in unique_geos:\n",
        "    geos_encode[geo] = i\n",
        "    i += 1\n",
        "  return geos_encode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PU9gyPPWr_qU"
      },
      "outputs": [],
      "source": [
        "G_train = create_graph(df[(df.year >= 2012) & (df.year < 2016)])\n",
        "G_val = create_graph(df[df.year == 2016])\n",
        "G_test = create_graph(df[df.year == 2017])\n",
        "common_authors_val = set(G_train.nodes).intersection(set(G_val.nodes))\n",
        "common_authors_test = set(G_train.nodes).intersection(set(G_test.nodes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8IqQnN-pD29"
      },
      "outputs": [],
      "source": [
        "geos_encode = get_geos_encode(df)\n",
        "\n",
        "def get_data(df, F, geos_encode):\n",
        "  data = []\n",
        "  G = add_sim(create_graph(df), F)\n",
        "  for u, v in combinations(G.nodes(), 2):\n",
        "    if G.has_edge(u, v):\n",
        "      data.append([u, v, geos_encode[G.nodes[u]['geo']], geos_encode[G.nodes[v]['geo']], G[u][v]['sim'], 1])\n",
        "    else:\n",
        "      data.append([u, v, geos_encode[G.nodes[u]['geo']], geos_encode[G.nodes[v]['geo']], SIM(u, v, G, F), 0])\n",
        "  return pd.DataFrame(data, columns=['author_1', 'author_2', 'author_1_a', 'author_2_a',  'sim', 'label'])\n",
        "\n",
        "train_data = get_data(df[df.year < 2016], F, geos_encode)\n",
        "val_data = get_data(df[df.year == 2016], F, geos_encode)\n",
        "test_data = get_data(df[df.year == 2017], F, geos_encode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBVePWssoxlS"
      },
      "outputs": [],
      "source": [
        "def get_data_without_aff(df, F):\n",
        "  data = []\n",
        "  G = add_sim(create_graph(df), F)\n",
        "  for u, v in combinations(G.nodes(), 2):\n",
        "    if G.has_edge(u, v):\n",
        "      data.append([u, v, G.nodes[u]['geo']==G.nodes[v]['geo'], G[u][v]['sim'], 1])\n",
        "    else:\n",
        "      data.append([u, v, G.nodes[u]['geo']==G.nodes[v]['geo'], SIM(u, v, G, F), 0])\n",
        "  return pd.DataFrame(data, columns=['author_1', 'author_2', 'same_a',  'sim', 'label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5ZjVb7zpkqd"
      },
      "outputs": [],
      "source": [
        "def get_data_with_n_count(df, F):\n",
        "  data = []\n",
        "  G = add_sim(create_graph(df), F)\n",
        "  for u, v in combinations(G.nodes(), 2):\n",
        "    if G.has_edge(u, v):\n",
        "      data.append([u, v, int(G.nodes[u]['geo']==G.nodes[v]['geo']), len(list(nx.common_neighbors(G, u, v))), G[u][v]['sim'], 1])\n",
        "    else:\n",
        "      data.append([u, v, int(G.nodes[u]['geo']==G.nodes[v]['geo']), len(list(nx.common_neighbors(G, u, v))), SIM(u, v, G, F), 0])\n",
        "  return pd.DataFrame(data, columns=['author_1', 'author_2', 'same_a', 'cn',  'sim', 'label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "TmgN479Zqmyd",
        "outputId": "666a557e-5172-43ba-8a7f-1c506a6bd1ef"
      },
      "outputs": [],
      "source": [
        "train_data = get_data_with_n_count(df[df.year < 2016], F)\n",
        "val_data = get_data_with_n_count(df[df.year == 2016], F)\n",
        "test_data = get_data_with_n_count(df[df.year == 2017], F)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zZCP78Er7E8"
      },
      "outputs": [],
      "source": [
        "train_data.to_csv(gDrivePath + 'train_with_n.csv')\n",
        "val_data.to_csv(gDrivePath + 'val_with_n.csv')\n",
        "test_data.to_csv(gDrivePath + 'test_with_n.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BowrKf7PpHhQ",
        "outputId": "b2ad7ccc-a16c-41eb-cc1f-db669ed3cf5a"
      },
      "outputs": [],
      "source": [
        "#train_data_a = get_data_without_aff(df[df.year < 2016], F)\n",
        "#val_data_a = get_data_without_aff(df[df.year == 2016], F)\n",
        "#test_data_a = get_data_without_aff(df[df.year == 2017], F)\n",
        "#test_data_a = test_data_a[test_data_a.author_1.isin(common_authors_test) & test_data_a.author_2.isin(common_authors_test)]\n",
        "#val_data_a = val_data_a[val_data_a.author_1.isin(common_authors_val) & val_data_a.author_2.isin(common_authors_val)]\n",
        "train_data = pd.read_csv(gDrivePath + 'train_a.csv')\n",
        "test_data = pd.read_csv(gDrivePath + 'test_a.csv')\n",
        "val_data = pd.read_csv(gDrivePath + 'val_a.csv')\n",
        "print(test_data.shape, val_data.shape, train_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "-ogjVRnfv_LL",
        "outputId": "040dc93d-d1de-4084-877b-a2e86d8604d1"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "train_data_a['dummy'] = 0\n",
        "plt.figure(figsize=(14, 10))\n",
        "plt.xticks(rotation = 90)\n",
        "sns.violinplot(y=\"sim\", x=\"same_a\", hue=\"label\", data=train_data_a, palette=\"pastel\", split=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kmk-dM1cVay"
      },
      "outputs": [],
      "source": [
        "# train_data_a.to_csv(gDrivePath + 'train_a.csv', index=False)\n",
        "# test_data_a.to_csv(gDrivePath + 'test_a.csv', index=False)\n",
        "# val_data_a.to_csv(gDrivePath + 'val_a.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSo6GeXeKTS_",
        "outputId": "159d8936-cba1-4ba0-aae8-aed25521e5a1"
      },
      "outputs": [],
      "source": [
        "test_data = test_data[test_data.author_1.isin(common_authors_test) & test_data.author_2.isin(common_authors_test)]\n",
        "val_data = val_data[val_data.author_1.isin(common_authors_val) & val_data.author_2.isin(common_authors_val)]\n",
        "print(test_data.shape, val_data.shape, train_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HSiRmfeV8AH"
      },
      "outputs": [],
      "source": [
        "train_data.to_csv(gDrivePath + 'train.csv', index=False)\n",
        "test_data.to_csv(gDrivePath + 'test.csv', index=False)\n",
        "val_data.to_csv(gDrivePath + 'val.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skcydchUuqOh"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv(gDrivePath + 'train_a.csv')\n",
        "test_data = pd.read_csv(gDrivePath + 'test_a.csv')\n",
        "val_data = pd.read_csv(gDrivePath + 'val_a.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoeyZtYjfJw6",
        "outputId": "acff9c72-025d-4cff-c678-b4f77638ea29"
      },
      "outputs": [],
      "source": [
        "test_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKX4qcbsDNie"
      },
      "source": [
        "# Treshold method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ay2fKU7TK2Ti"
      },
      "outputs": [],
      "source": [
        "def calculateSim(G, F):\n",
        "  n = G.number_of_nodes()\n",
        "  d = sparse.lil_matrix((n, n), dtype=float)\n",
        "  for i1, n1 in enumerate(G.nodes):\n",
        "        for i2, n2 in enumerate(G.nodes):\n",
        "            if n1 != n2:\n",
        "                d[i2,i1] = SIM(n1, n2, G, F)\n",
        "  return d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbhlEedAhCFG"
      },
      "outputs": [],
      "source": [
        "sims = calculateSim(G_train, F)\n",
        "df_train_sim = pd.DataFrame(sims.todense(), columns=G_train.nodes, index=G_train.nodes)\n",
        "df_train_sim_ca = df_train_sim.loc[common_authors_val, common_authors_val]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XH6VUd8DiYXL"
      },
      "outputs": [],
      "source": [
        "#матрица смежности для тестового набора\n",
        "test_adj = nx.adjacency_matrix(G_val).todense()\n",
        "# то же, только с именами\n",
        "df_test_adj = pd.DataFrame(test_adj, columns=G_val.nodes, index=G_val.nodes)\n",
        "# то же, только для авторов из обоих наборов (train - test)\n",
        "df_test_adj_ca = df_test_adj.loc[common_authors_val, common_authors_val]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6SvBOXXLxxy"
      },
      "outputs": [],
      "source": [
        "#матрица смежности для тестового набора\n",
        "test_adj = nx.adjacency_matrix(G_test).todense()\n",
        "# то же, только с именами\n",
        "df_test_adj = pd.DataFrame(test_adj, columns=G_test.nodes, index=G_test.nodes)\n",
        "# то же, только для авторов из обоих наборов (train - test)\n",
        "df_test_adj_ca = df_test_adj.loc[common_authors_test, common_authors_test]\n",
        "df_train_sim_ca = df_train_sim.loc[common_authors_test, common_authors_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t624G4zSL4dS",
        "outputId": "9083ad4a-13b2-4e69-f9de-b1f550ba32cd"
      },
      "outputs": [],
      "source": [
        "#Сколько должно быть общих соседей чтобы сказать что между вершинами будет связь?\n",
        "threshold = 0.791\n",
        "#Матрица смежности для связей которые могут быть в будущем\n",
        "mask = (df_train_sim_ca > threshold).astype(int)\n",
        "#сколько ребер предсказано верно\n",
        "\n",
        "#точность предсказания связей графа\n",
        "precision = precision_score(df_test_adj_ca.values.flatten(), mask.values.flatten())\n",
        "recall = recall_score(df_test_adj_ca.values.flatten(), mask.values.flatten())\n",
        "f3 = 10 * recall * precision / (9 * precision + recall)\n",
        "print('Precision ' + str(precision))\n",
        "print('Recall ' + str(recall))\n",
        "print('F3 ' + str(f3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCC_i0pma205"
      },
      "source": [
        "# TM + affiliations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nw6cuYHIIp5h"
      },
      "outputs": [],
      "source": [
        "X_train = train_data.drop('author_1', axis=1).drop('author_2', axis=1).drop('label', axis=1)\n",
        "y_train = train_data['label']\n",
        "X_test = test_data.drop('author_1', axis=1).drop('author_2', axis=1).drop('label', axis=1)\n",
        "y_test = test_data['label']\n",
        "X_val = val_data.drop('author_1', axis=1).drop('author_2', axis=1).drop('label', axis=1)\n",
        "y_val = val_data['label']\n",
        "cat_feat = ['same_a']\n",
        "test = cgb.Pool(data=X_test, label=y_test, cat_features=cat_feat)\n",
        "val = cgb.Pool(data=X_val, label=y_val, cat_features=cat_feat)\n",
        "train = cgb.Pool(data=X_train, label=y_train, cat_features=cat_feat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "86nrdpE7bRWD",
        "outputId": "ed7d3bbb-00fb-4f83-f95f-85380c38db5b"
      },
      "outputs": [],
      "source": [
        "def score(params):\n",
        "  model = cgb.CatBoostClassifier(**params, task_type=\"GPU\", logging_level='Silent')\n",
        "  model.fit(train, eval_set=val)\n",
        "  metrics = model.eval_metrics(val, ['F1:use_weights=false'])\n",
        "\n",
        "  return {'loss': -metrics['F1:use_weights=false'][-1], 'status': STATUS_OK}\n",
        "\n",
        "space = {\n",
        "    'loss_function': 'Logloss',\n",
        "    'eval_metric': 'F1:use_weights=false',\n",
        "    'iterations': hp.choice('iterations', np.arange(50, 500, 50)),\n",
        "    'learning_rate': hp.uniform('learning_rate', 0.1, 1),\n",
        "    'random_seed': 42,\n",
        "    'l2_leaf_reg': hp.uniform('l2_leaf_reg', 0, 20),\n",
        "    'depth': hp.choice('depth', np.arange(3, 16, 1)),\n",
        "    'min_data_in_leaf': hp.uniform('min_data_in_leaf', 0, 10),\n",
        "    #'max_leaves': hp.choice('max_leaves', np.arange(20, 64, 1)),\n",
        "    'auto_class_weights': hp.choice('auto_class_weights', ['Balanced', 'SqrtBalanced']),\n",
        "          }\n",
        "\n",
        "def optimize(trials, space):\n",
        "  best = fmin(score, space, algo = tpe.suggest, max_evals = 400)\n",
        "  return best\n",
        "\n",
        "trials = Trials()\n",
        "best_params = optimize(trials, space)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmdcEPMq4VX_"
      },
      "source": [
        "# Классификатор (CatBoost)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkY8TE53Hked"
      },
      "outputs": [],
      "source": [
        "model = cgb.CatBoostClassifier(loss_function='Logloss',\n",
        "                               eval_metric='F1:use_weights=false',\n",
        "                               random_seed=42,\n",
        "                               auto_class_weights='SqrtBalanced',\n",
        "                               iterations = 70,\n",
        "                               logging_level='Verbose')\n",
        "model.fit(train, eval_set=val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBE7h_a6w7oY"
      },
      "outputs": [],
      "source": [
        "def findBestTresholdForF1(probs, y):\n",
        "  best_f1 = 0\n",
        "  treshold = 0\n",
        "  for prob in set(probs):\n",
        "    preds = (probs > prob).astype(int)\n",
        "    f1 = f1_score(y, preds)\n",
        "    if f1 > best_f1:\n",
        "      best_f1 = f1\n",
        "      treshold = prob\n",
        "  return best_f1, treshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gUx_siYHkee",
        "outputId": "af6bf055-54b9-45fd-c293-7e3f512dec64"
      },
      "outputs": [],
      "source": [
        "probs = model.predict_proba(test)\n",
        "f1, tresh = findBestTresholdForF1(probs[:, 1], test.get_label())\n",
        "preds = (probs[:, 1] > tresh).astype(int)\n",
        "f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xS2IBTfkPKh5"
      },
      "outputs": [],
      "source": [
        "model.eval_metrics(test, ['PRAUC:use_weights=false', 'F1:use_weights=false', 'AUC:use_weights=false', 'Precision:use_weights=false', 'Recall:use_weights=false'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXWlN2e4tFN_",
        "outputId": "809378a6-7e82-45c4-f980-18f257f957b3"
      },
      "outputs": [],
      "source": [
        "test.get_label().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MY8m3-NxrNjE",
        "outputId": "cae8dbbf-3db8-4b88-bc40-d46b3c9bcde5"
      },
      "outputs": [],
      "source": [
        "cgb.utils.get_confusion_matrix(model, test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhz9Oj7MHkeg"
      },
      "outputs": [],
      "source": [
        "metrics = model.eval_metrics(val, ['AUC', 'Precision', 'BalancedAccuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jwx9SfONHkeg",
        "outputId": "f72a8660-ac9f-45a7-a945-db442f950cba"
      },
      "outputs": [],
      "source": [
        "def predict(model, train, test):\n",
        "  roc_curve_values = get_roc_curve(model, train)\n",
        "  boundary = select_threshold(model, curve=roc_curve_values, FPR=0.9)\n",
        "  print(boundary)\n",
        "  proba = model.predict_proba(test)\n",
        "  predicted = (proba[:, 1] >  boundary).astype(int)\n",
        "  return predicted, proba[:, 1]\n",
        "\n",
        "predicted, proba = predict(model, train, val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDe9PW1gudRJ",
        "outputId": "dbb12f5d-90cf-4818-ec90-511f0cc69f28"
      },
      "outputs": [],
      "source": [
        "predicted = -1 * predicted + 1\n",
        "actual = -1 * val.get_label() + 1\n",
        "tp = (predicted * actual).sum()\n",
        "print(roc_auc_score(actual, 1 - proba), tp / predicted.sum())\n",
        "print(predicted.sum(), tp.sum())\n",
        "print(actual.sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViGgFsfzHkeh"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (14,10))\n",
        "plt.plot(np.arange(len(metrics['Precision'])), metrics['Precision'], label = 'Pr')\n",
        "plt.plot(np.arange(len(metrics['AUC'])), metrics['AUC'], label = 'AUC')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0ybv3a6sM0D"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (14,10))\n",
        "plt.plot(np.arange(len(metrics['Precision'])), metrics['Precision'], label = 'Pr')\n",
        "plt.plot(np.arange(len(metrics['AUC'])), metrics['AUC'], label = 'AUC')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CPty-Agc94W"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4igS6l8dAoQ"
      },
      "source": [
        "# Classifier (Desision tree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQFu9DybdFim"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import export_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iG5Zx-MFebXR",
        "outputId": "a513708f-b783-4f52-d749-6c8b3fcbe7c1"
      },
      "outputs": [],
      "source": [
        "clf = DecisionTreeClassifier(random_state=42, class_weight = 'balanced')\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylOTSzTtHye5",
        "outputId": "82bd73c1-3c23-40e6-97b5-036561e5b97b"
      },
      "outputs": [],
      "source": [
        "train_data[train_data.label == 0].shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Dz6RTltBILx",
        "outputId": "8c1225ea-34aa-48e3-eabb-cb46f276eec9"
      },
      "outputs": [],
      "source": [
        "probs = clf.predict_proba(X_test)\n",
        "f1, tresh = findBestTresholdForF1(probs[:, 1], y_test)\n",
        "preds = (probs[:, 1] > tresh).astype(int)\n",
        "roc_auc_score(y_test, probs[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c79OdZPe_AH",
        "outputId": "3c74238f-d765-40d6-c8f3-a34481e88302"
      },
      "outputs": [],
      "source": [
        "classification_report(y_val, clf.predict(X_val), output_dict=True)['1']['f1-score']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbVdWHHyfnUE"
      },
      "outputs": [],
      "source": [
        "def score(params):\n",
        "  clf = DecisionTreeClassifier(random_state=42, class_weight = 'balanced')\n",
        "  clf.fit(X_train, y_train)\n",
        "  f1 = classification_report(y_val, clf.predict(X_val), output_dict=True)['1']['f1-score']\n",
        "  return {'loss': -f1, 'status': STATUS_OK}\n",
        "\n",
        "space = {\n",
        "    'max_depth': hp.choice('max_depth', np.arange(3, 16, 1)),\n",
        "    'min_samples_split': hp.choice('min_samples_split', np.arange(2, 5, 1)),\n",
        "    'min_samples_leaf': hp.choice('min_samples_leaf', np.arange(1, 5, 1)),\n",
        "    'max_features': hp.choice('max_features', [1, 2]),\n",
        "    'max_leaf_nodes': hp.choice('max_leaf_nodes', range(5, 64, 5)),\n",
        "    'ccp_alpha': hp.uniform('ccp_alpha', 0, 10)\n",
        "}\n",
        "\n",
        "def optimize(trials, space):\n",
        "  best = fmin(score, space, algo = tpe.suggest, max_evals = 1000)\n",
        "  return best\n",
        "\n",
        "trials = Trials()\n",
        "best_params = optimize(trials, space)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "by0NilQOjjTN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "i0vEZF6v4lbi"
      ],
      "name": "LinkPrediction.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
